[
  {
    "objectID": "overview.html#areal-av-isbreer-glacier-area",
    "href": "overview.html#areal-av-isbreer-glacier-area",
    "title": "Overview of indicators",
    "section": "Areal av isbreer / Glacier area",
    "text": "Areal av isbreer / Glacier area\nThis indicator reflects the relative loss of glacial area between tha last climatic normal persion and today.\n\n\n\n\nFakatark for tilstandindikatoren  Areal av isbreer \n\n  \n    Indikator \n    Areal av isbreer \n  \n  \n    Utfylling.av.protokollen \n    Anders L. Kolstad \n  \n  \n    Data.utfylt.revidert \n    08.12.2021"
  },
  {
    "objectID": "overview.html#indicator-x",
    "href": "overview.html#indicator-x",
    "title": "Overview of indicators",
    "section": "Indicator X",
    "text": "Indicator X\nAnd this indicator is about…"
  },
  {
    "objectID": "indicatorTest.html",
    "href": "indicatorTest.html",
    "title": "(PART*) INDICATORS FOR WETLANDS",
    "section": "",
    "text": "This is an indicator\n\n\n\n\n\n\n\n\n\nEcosystem\nØkologisk.egenskap\nECT.class\n\n\n\n\nSkog og fjell\nPrimærproduksjon\nStructural state characteristic\n\n\n\n\n\n \n\n\nplot(rnorm(10,10,10))"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ecosystemCondition",
    "section": "",
    "text": "About\nOn this site you may view the details for how certain indicators for ecosystem condition for Norway have been calculated.\nThe web page is made to document the work related to a R&D project to develop indicators for ecosystem condition for three main ecosystems in Norway: wetlands, open areas below the forest line, and semi-natural land. These indicators are not yet used in real assessments, and may represent unfinished work pending future data availability. In addition, we may chose to also present some analyses documenting indicators that are used in existing assessments of ecosystem condition."
  },
  {
    "objectID": "index.html#eatools",
    "href": "index.html#eatools",
    "title": "ecosystemCondition",
    "section": "eaTools ",
    "text": "eaTools \neaTools is an R package aimed at solving common tasks in GIS oriented ecosystem accounting, especially ecosystem condition accounting. We will use functions from this package, such as this function to normalise condition variables seen in Figure @ref(fig:eaTools-example).\n\n#devtools::install_github(\"NINAnor/eaTools\")\nlibrary(eaTools)\n\n# Import example data\ndata(\"ex_polygons\")\n\n# Use the questionmark to readabout the example data sets or to view the  function documentation \n#?ex_polygons\n\neaTools::ea_normalise(data = ex_polygons,\n             vector = \"condition_variable_2\",\n             upper_reference_level = 7,\n             scaling_function = \"sigmoid\",\n             plot = T)\n\n\n\n\nA normalised condition variable is called an indicator. This indicator had been transformed with a sigmoid function.\n\n\n\n\nSee the package documentation, especially under Articles for more information and examples of use."
  },
  {
    "objectID": "index.html#community-review",
    "href": "index.html#community-review",
    "title": "ecosystemCondition",
    "section": "Community review",
    "text": "Community review\nWe want our work to be transparent and credible. Therefor we encourage all types of feedback on the analyses of the indicators for ecological condition that you can read about on this web site. To submit your comments, please to to this github repository and open a new issue and we will answer them there."
  },
  {
    "objectID": "index.html#author-guidelines",
    "href": "index.html#author-guidelines",
    "title": "ecosystemCondition",
    "section": "Author guidelines",
    "text": "Author guidelines\nThis project uses a type of standardised reporting where reproducible workflows (typically code) for calculating each indicator is presented on separate webpages within a shared website. The website is built from the GitHub repo using seperate RMarkdown files for each chapter. These files must be in English. The process of authoring and sharing/distributing these Rmarkdown-files is explained below.\nIt is highly encouraged that the indicators are delivered as georeferenced maps, hereafter called indicator maps, and not a simple tables. There is a common structure that all indicator maps should follow. The indicator maps can be vector formats raster formats. For vector data, .Rdata or .rds files can be used, as for example shape files do not allow field names (i.e. column names) that are as long as the ones we use. All georeferenced data should use EPSG:25833 - ETRS89 / UTM zone 33N.\nIndicator maps should have the highest possible spatial resolution possible but weighing this against the need for spatial representativity. For example, you may need to aggregate x number of data points to get an average which is stable and representative for a given region. There is no need to spatially aggregate indicator maps any further, for example to produce a national estimate.\nThe indicator values, reference values ect should be mapped to the following columns (vector data) or bands (raster data):\n\nv_YYYY for variable value (i.e. un-scaled or raw indicator values) for year YYYY.\nsd_YYYY for the standard deviation associated with v_YYYY. Other measures for uncertainty is currently not supported.\nreferance_high for the reference value, i.e. the value of the variable v under reference conditions. This value cannot vary between years.\nreferance_low for the lower limit reference value, i.e. the worst possible value of the variable v. This value cannot vary between years. If missing, this value is assumed to be zero.\nthr for the threshold value defining good condition for variable v. If missing, this value will default to 0.6.\ni_YYYY for the indicator value at year YYYY. This value depends on all the above values, but also the scaling function (.e. linear, exponential, two-sided, ect.). The scaling function needs to be presented in other documentation.\n\nThe rest of the workflow is as follows.\n\nObtain a go ahead signal from the coordination group to make sure you are free to start your work\nRead the template.Rmd file. Make a copy of it and store it, in the same (root) folder as DRAFT_myIndicator.Rmd. (For an example, see DRAFT_breareal.Rmd). Finish your documentation and analyses there.\n\nYou can load data from internal NINA servers, from web hosts, of store smaller data set under data. The data folder also contains some supporting data sets that you may want to use, such as a delineation of the five regions used in the ecosystem assessment (data/regions.shp), and an outline of Norway (outlineOfNorway_EPSG25833.shp).\nTo preview you rmarkdown file as html in R, type rmarkdown::render('DRAFT_myIndicator.Rmd', output_format = \"html_document\", output_dir = \"temp\") in the console (the knitr shortcuts don’t work as expected inside bookdown projects).\nWhen filling out the template.Rmd file with your own work, try not to change the headers too much.\nFinal result from the analyses should be written to the indicators folder. The preferred output is georeferenced data (rasters or shape files), and these should be placed under indators/indicatorMaps. Non-georeferenced data, like data tables, can be stored under indicators.\n\nMake a pull request to the main GitHub repository to submit your file. If you are not comfortable using GitHub, contac Anders to rrange sending the files via email.\nAnders or someone else in the project wil conduct a rapid code review, making sure the code is reproducible, interpretable and that it renders locally on the R Studio server.\nWhen approved, the reviewer will make a copy of the DRAFT_ file, removing the DRAFT_ part of the name, as well as the YML header, and as well as updating the rmd_files part of _bookdown.yml. (For an example of such a file, see breareal.Rmd.)\nTo update the web site (this web site), an admin user needs to pull down the repo to R Studio server, compile the book there (Ctr+Shift+B), commit and push to main. The html version of the book will be in the docs folder."
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "ecosystemCondition",
    "section": "Citation",
    "text": "Citation\nTo cite this book please use the following citation:\nKolstad, A.L., Topper, J. Grainger, M.J., Sandvik, H. Indicators for Ecosystem Condition in Norway. https://ninanor.github.io/ecosystemCondition/index.html.doi [TBA]"
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "ecosystemCondition",
    "section": "License",
    "text": "License\nThe book is licensed under a CC By 4.0 licence which means that you can share and adapt the material for any purpose. However, you must give appropriate credit, provide a link to the license, and indicate if changes were made. You can not add additional restrictions on the material even when adapted."
  },
  {
    "objectID": "master_grid.html#introduction",
    "href": "master_grid.html#introduction",
    "title": "8  Master grid",
    "section": "8.1 Introduction",
    "text": "8.1 Introduction\nThis chapter describes the making of a master raster grid for all of mainland Norway. This grid is used to align all ecosystem and indicator maps so that it becomes possible to do easy resamping, masking and aggregating.\nTo do : I plan to add examples how to use this master grid on real data."
  },
  {
    "objectID": "master_grid.html#about-the-underlying-data",
    "href": "master_grid.html#about-the-underlying-data",
    "title": "8  Master grid",
    "section": "8.2 About the underlying data",
    "text": "8.2 About the underlying data\nI will use the statistical grid from Norway (5x5km) and resample this to a higher resolution of 50 x 50 meters."
  },
  {
    "objectID": "master_grid.html#analyses",
    "href": "master_grid.html#analyses",
    "title": "8  Master grid",
    "section": "8.3 Analyses",
    "text": "8.3 Analyses\n\n# Set up conditional file paths\ndir <- substr(getwd(), 1,2)\n\npData <- ifelse(dir == \"C:\", \n               \"P:/41201785_okologisk_tilstand_2022_2023/data/\",\n               \"/data/P-Prosjekter2/41201785_okologisk_tilstand_2022_2023/data/\")\n\nImport data\n\n#st_layers(paste0(pData, \"Basisdata_0000_Norge_25833_StatistiskRutenett5km_FGDB.gdb\"))\ngrid_5km <- sf::read_sf(paste0(pData, \"Basisdata_0000_Norge_25833_StatistiskRutenett5km_FGDB.gdb\")) \n\n\ntmap_mode(\"view\")\ntm_shape(grid_5km$SHAPE)+\n  tm_borders()\n\n\nConfirming CRS is EPSG25833:\n\nst_crs(grid_5km)\n\nCoordinate Reference System:\n  User input: ETRS89 / UTM zone 33N \n  wkt:\nPROJCRS[\"ETRS89 / UTM zone 33N\",\n    BASEGEOGCRS[\"ETRS89\",\n        ENSEMBLE[\"European Terrestrial Reference System 1989 ensemble\",\n            MEMBER[\"European Terrestrial Reference Frame 1989\"],\n            MEMBER[\"European Terrestrial Reference Frame 1990\"],\n            MEMBER[\"European Terrestrial Reference Frame 1991\"],\n            MEMBER[\"European Terrestrial Reference Frame 1992\"],\n            MEMBER[\"European Terrestrial Reference Frame 1993\"],\n            MEMBER[\"European Terrestrial Reference Frame 1994\"],\n            MEMBER[\"European Terrestrial Reference Frame 1996\"],\n            MEMBER[\"European Terrestrial Reference Frame 1997\"],\n            MEMBER[\"European Terrestrial Reference Frame 2000\"],\n            MEMBER[\"European Terrestrial Reference Frame 2005\"],\n            MEMBER[\"European Terrestrial Reference Frame 2014\"],\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[0.1]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4258]],\n    CONVERSION[\"UTM zone 33N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",15,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Europe between 12°E and 18°E: Austria; Denmark - offshore and offshore; Germany - onshore and offshore; Norway including Svalbard - onshore and offshore.\"],\n        BBOX[46.4,12,84.42,18]],\n    ID[\"EPSG\",25833]]\n\n\n\n8.3.1 Make grid\nUse the bbox and split into 50 x 50 meter cells\n\n(masterGrid_50m <- st_as_stars(st_bbox(grid_5km), dx = 50, dy = 50))\n\nstars object with 2 dimensions and 1 attribute\nattribute(s), summary of first 1e+05 cells:\n        Min. 1st Qu. Median Mean 3rd Qu. Max.\nvalues     0       0      0    0       0    0\ndimension(s):\n  from    to  offset delta                refsys x/y\nx    1 24500  -1e+05    50 ETRS89 / UTM zone 33N [x]\ny    1 30800 7965000   -50 ETRS89 / UTM zone 33N [y]\n\n\nThis file is 6GB.\nNumber of cells, in millions, is:\n\n(nrow(masterGrid_50m)*ncol(masterGrid_50m))/10^6\n\n    x \n754.6 \n\n\nSo, quite a lot. For the area accounts we might consider using 10x10m.\n\n\n8.3.2 Eksport file (final product)\n\nstars::write_stars(masterGrid_50m, paste0(pData, \"masterGrid_50m.tiff\"))\n\n\n\n8.3.3 Test import\n\ntemp <- stars::read_stars(paste0(pData, \"masterGrid_50m.tiff\"))\nst_dimensions(temp)\n\n  from    to  offset delta                refsys point x/y\nx    1 24500  -1e+05    50 ETRS89 / UTM zone 33N FALSE [x]\ny    1 30800 7965000   -50 ETRS89 / UTM zone 33N FALSE [y]"
  },
  {
    "objectID": "homogeneous_impact_areas.html#introduction",
    "href": "homogeneous_impact_areas.html#introduction",
    "title": "7  Homogeneous Impact Areas",
    "section": "7.1 Introduction",
    "text": "7.1 Introduction\nThis chapter documents the creation of a wall-to-wall map of homogeneous impact areas in Norway. The map is produced by binning values in the infrastructure index into four discrete categories. It is likely to be a good predictor for some indicators, such as slitasje and the presence of alien species."
  },
  {
    "objectID": "homogeneous_impact_areas.html#about-the-underlying-data",
    "href": "homogeneous_impact_areas.html#about-the-underlying-data",
    "title": "7  Homogeneous Impact Areas",
    "section": "7.2 About the underlying data",
    "text": "7.2 About the underlying data\nThe infrastructure index is explained here. It is a wall-to-wall raster over Norway with 100 m resolution. Each pixel is given a value along a continuous gradient from 0 to around 15.4, representing the frequency of surrounding cells within 500 m with human infrastructure (houses, roads, ect).\n\n7.2.1 Representativity in time and space\nThe infrastructure index is calculated with data that have slightly different dates, but can be said to represent year 2015. The data covers all of mainland Norway.\n\n\n7.2.2 References\nBakkestuen, V., Dervo, B.K., Bærum, K.M. og Erikstad, L. 2022. Prediksjonsmodellering av naturtyper i ferskvann. NINA Rapport 2079. Norsk institutt for naturforskning."
  },
  {
    "objectID": "homogeneous_impact_areas.html#analyses",
    "href": "homogeneous_impact_areas.html#analyses",
    "title": "7  Homogeneous Impact Areas",
    "section": "7.3 Analyses",
    "text": "7.3 Analyses\n\n7.3.1 Import data\nThe path must be conditional:\n\ndir <- substr(getwd(), 1,2)\n\n\npath <- ifelse(dir == \"C:\", \n        \"R:/GeoSpatialData/Utility_governmentalServices/Norway_Infrastructure_Index/Original/Infrastrukturindeks_UTM33/infra_tiff.tif\",\n        \"/data/R/GeoSpatialData/Utility_governmentalServices/Norway_Infrastructure_Index/Original/Infrastrukturindeks_UTM33/infra_tiff.tif\")\n\nImport a stars proxy (no data imported yet)\n\ninfra <- stars::read_stars(path)\n\nPrint the coordinate reference system:\n\nst_crs(infra)$input\n\n[1] \"WGS_1984_UTM_Zone_33N\"\n\n\n\n\n7.3.2 Trondheim example\nIt’s easier to see what’s happening if we zoom in a bit. Lets get a boundary box around Trondheim.\n\nmyBB <- st_bbox(c(xmin=260520.12, xmax = 278587.56,\n                ymin = 7032142.5, ymax = 7045245.27),\n                crs = st_crs(infra))\n\nCropping the raster to the bbox\n\ninfra_trd <- sf::st_crop(infra, myBB)\n\n\n7.3.2.1 Get OSM highways\nLets download some base maps to help validate and contextualize the infrastructure index.\nTransform to lat long due to osm requirements\n\ninfra_trd_ll <- sf::st_transform(infra_trd, 4326)\n\nGet the boundary box of the cropped raster\n\nmyBB_ll <- sf::st_bbox(infra_trd_ll)\n\nDownload highways using the above bbox.\n\nhw <- \n  osmplotr::extract_osm_objects(\n    bbox = myBB_ll,\n    key = \"highway\",\n    sf = T)\n\nTransforming highway data back into utm, although not strictly necessary.\n\nhw_utm <- sf::st_transform(hw, sf::st_crs(infra_trd)) \n\nThis object contains too many roads (about 30k). I’ll take out the unnamed roads.\n\nhw_utm <- hw_utm[!is.na(hw_utm$name),]\n\n\n\n\n\n\n\n\n\n7.3.2.2 Discretize\nHere I define a simplified categorical typology for the infrastructure index using four classes.\n\nnames(infra_trd) <- \"infrastructureIndex\"\ninfra_trd_reclassed <-  infra_trd %>%\n  mutate(infrastructureIndex = case_when(\n    infrastructureIndex < 1 ~ 0,\n    infrastructureIndex < 6 ~ 1,\n    infrastructureIndex < 12 ~ 2,\n    infrastructureIndex >= 12 ~ 3\n  ))\n\nLets plot these two maps side by side\n\nmap_trd_reclassed <- tm_shape(infra_trd_reclassed)+\n  tm_raster(title=\"Infrastructure Index\",\n            #palette = \"viridis\",\n            style=\"cat\")+\n  tm_layout(legend.outside = T)+\n  tm_shape(hw_utm)+\n  tm_lines(col=\"white\")\n\n\nmap_trd <- tm_shape(infra_trd)+\n  tm_raster(title=\"Infrastructure Index\",\n            style=\"cont\",\n            palette = \"viridis\")+\n  tm_layout(legend.outside = T)+\n  tm_shape(hw_utm)+\n  tm_lines(col=\"white\")\n\n\ntmap_arrange(map_trd,\n             map_trd_reclassed,\n             ncol=1)\n\nstars_proxy object shown at 181 by 132 cells.\nstars_proxy object shown at 181 by 132 cells.\n\n\n\n\n\nInfrastructure index over Trondheim, comparing the continous scale with the ordinal four-step scale. Major roads are in white.\n\n\n\n\nI tweaked the thresholds for the bins so that the categories match my knowledge about the land use intensity in Trondheim, for example that most of the forest next to Trondheim (to the left in the map) was in the second lowest class. This looks pretty good to me. It depicts a gradient in human presence from high within the built zone, to no to very low in the forests and mountains to the west. Note that there is still considerable human activity also there in the form of outdoor recreation and even forestry.\n\n\n7.3.2.3 Aggregate\nThe resolution in this map is more than we need, and the size of the data implies that the next step, the vectorization, would take too long. We therefore aggregate, or reduce the resolution.\n\ndim <- st_dimensions(infra)\npaste(\"Resolution is\", dim$x$delta, \"by\", dim$x$delta, \"meters\")\n\n[1] \"Resolution is 100 by 100 meters\"\n\n\n\ninfra_trd_reclassed_agg <- st_warp(infra_trd_reclassed, cellsize = c(1000, 1000), \n                                   crs = st_crs(infra_trd_reclassed), \n                                   use_gdal = TRUE,\n                                   method = \"average\")\n\n\ndim <- st_dimensions(infra_trd_reclassed_agg)\npaste(\"Resolution is\", dim$x$delta, \"by\", dim$x$delta, \"meters\")\n\n[1] \"Resolution is 1000 by 1000 meters\"\n\n\nEach cell is now the average of the aggregated cells, and hence the value is continuous again. Let’s make it discrete.\n\nnames(infra_trd_reclassed_agg) <- \"infrastructureIndex\"\ninfra_trd_reclassed_agg <-  infra_trd_reclassed_agg %>%\n  mutate(infrastructureIndex = case_when(\n    infrastructureIndex < 1 ~ 0,\n    infrastructureIndex < 6 ~ 1,\n    infrastructureIndex < 12 ~ 2,\n    infrastructureIndex >= 12 ~ 3\n  ))\n\n\ntm_shape(infra_trd_reclassed_agg)+\n  tm_raster(title=\"Infrastructure Index\",\n            style=\"cat\")+\n  tm_layout(legend.outside = T)+\n  tm_shape(hw_utm)+\n  tm_lines(col=\"white\")\n\n\n\n\nInfrastrcture index over Trondheim on a four-step discrete scale, aggregated to 1x1 km resolution using the mean function.\n\n\n\n\nThis resolution is more than good enough for our purpose here. I see that the map extends a bit into the fjord. We want to cut away these areas. We can use a map of the outline of Norway to do this.\n\noutline <- st_read(\"data/outlineOfNorway_EPSG25833.shp\")\n\nReading layer `outlineOfNorway_EPSG25833' from data source \n  `/data/scratch/Matt_bookdown__debug/ecosystemCondition/data/outlineOfNorway_EPSG25833.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1 feature and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -113472.7 ymin: 6448359 xmax: 1114618 ymax: 7939917\nProjected CRS: ETRS89 / UTM zone 33N\n\n\nThe CRS needs to be identical\n\ninfra_trd_reclassed_agg <- st_transform(infra_trd_reclassed_agg, 25833)\n\n\ninfra_trd_reclassed_agg_terrestrial <- st_crop(infra_trd_reclassed_agg, outline)\n\nWarning in st_crop.stars(infra_trd_reclassed_agg, outline): crop only crops\nregular grids\n\n\n\ntm_shape(infra_trd_reclassed_agg_terrestrial)+\n  tm_raster(title=\"Infrastructure Index\",\n            style=\"cat\")+\n  tm_layout(legend.outside = T)+\n  tm_shape(hw_utm)+\n  tm_lines(col=\"white\")+\n  tm_shape(outline)+\n  tm_borders(lwd =2,\n             col = \"black\")\n\n\n\n\nInfrastrcture index over Trondheim on a four-step discrete scale, aggregated to 1x1 km resolution using the mean function.\n\n\n\n\nI have treated the raster cells as points when cropping, so that cells where the center of the cell is outside the terrestrial delineation are removed. I think this makes the most sense for unbiased area statistics, but some coastal indicator data could also be excluded because of this. The errors would be smaller with a finer resolution raster, but computation time is a problem.\n\n\n\n7.3.3 Aggregate the entire map to 1x1 km\n\n# runtime about 30 sec\ninfra_agg <- st_warp(infra, cellsize = c(1000, 1000), \n                                   crs = st_crs(infra), \n                                   use_gdal = TRUE,\n                                   method = \"average\")\n# The CRS needs to be identical for st_crop\ninfra_agg <- st_transform(infra_agg, 25833)\n\n\n\n7.3.4 Cut out marine areas\nI see that the map extends a bit into the fjord. We want to cut away these areas. We can use a map of the outline of Norway to do this.\n\ninfra_agg_terrestrial <- st_crop(infra_agg, outline)\nsaveRDS(infra_agg_terrestrial, \"P:/41201785_okologisk_tilstand_2022_2023/data/cache/infra_agg_terrestrial.rds\")\n\n\n\n7.3.5 Discretize the entire map\n\nnames(infra_agg_terrestrial) <- \"infrastructureIndex\"\n\ninfra_agg_discrete <- infra_agg_terrestrial %>%\n  mutate(infrastructureIndex = case_when(\n    infrastructureIndex < 1 ~ 0,\n    infrastructureIndex < 6 ~ 1,\n    infrastructureIndex < 12 ~ 2,\n    infrastructureIndex >= 12 ~ 3\n  ))\n\n\n\n7.3.6 Vectorize\nThis step might seem rather stupid. We want to vectorize a rather large raster. This makes it a quite big data object. The reason is that there is no really good way to burn polygon data on to raster grid cells after the disuse of the {raster} package. It was not straight forward then either. But calculating intersections between polygons is very fast and easy.\n\ninfra_agg_discrete_vect <- \n  eaTools::ea_homogeneous_area(infra_agg_discrete, \n                                groups = infrastructureIndex)\npath <- ifelse(dir == \"C:\", \n        \"P:/41201785_okologisk_tilstand_2022_2023/data/cache/\",\n        \"/data/P-Prosjekter2/41201785_okologisk_tilstand_2022_2023/data/cache/\")\n\nsaveRDS(infra_agg_discrete_vect, paste0(path, \"infra_agg_discrete_vect.rds\"))\n\nLet’s plot this now. First, lets crop it to reduce computation time.\n\nmyBB <- st_bbox(c(xmin=260520.12, xmax = 278587.56,\n                ymin = 7032142.5, ymax = 7045245.27),\n                crs = st_crs(infra_agg_discrete_vect))\n\ninfra_agg_discrete_vect_trd <- st_crop(infra_agg_discrete_vect, myBB)\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n\n\ntm_shape(infra_agg_discrete_vect_trd)+\n  tm_polygons(col=\"infrastructureIndex\",\n              style = \"cat\")+\n  tm_layout(legend.outside = T)+\n  tm_shape(hw_utm)+\n  tm_lines(col=\"white\")\n\n\n\n\nA vectorized version of the Infrastructure index over Trondheim on a four-step discrete scale.\n\n\n\n\nAs can be seen in the figure above, st_warp merges grid cells that have the same value, and the vectorized raster doesn’t end up being that big in the end."
  },
  {
    "objectID": "homogeneous_impact_areas.html#check-national-distribution",
    "href": "homogeneous_impact_areas.html#check-national-distribution",
    "title": "7  Homogeneous Impact Areas",
    "section": "7.4 Check national distribution",
    "text": "7.4 Check national distribution\n\nregions <- sf::read_sf(\"data/regions.shp\", options = \"ENCODING=UTF8\")\nunique(regions$region)\n\n[1] \"Nord-Norge\" \"Midt-Norge\" \"Østlandet\"  \"Vestlandet\" \"Sørlandet\" \n\n\n\nst_crs(infra_agg_discrete_vect) == st_crs(regions)\n\n[1] TRUE\n\n\nSince the two layers are completely overlapping, we can get the intersections\n\ninfra_stats <- eaTools::ea_homogeneous_area(infra_agg_discrete_vect,\n                             regions,\n                             keep1 = \"infrastructureIndex\",\n                             keep2 = \"region\")\nsaveRDS(infra_stats, \"P:/41201785_okologisk_tilstand_2022_2023/data/cache/infra_stats.rds\")\n\nLet’s calculate the areas of these polygons and compare the HIF in the five regions.\n\ninfra_stats$area_km2 <- units::drop_units(sf::st_area(infra_stats))\ninfra_stats$area_km2 <- infra_stats$area_km2/1000\n\ntemp <- as.data.frame(infra_stats) %>%\n  group_by(region, infrastructureIndex) %>%\n  summarise(area_km2 = mean(area_km2))\n\n`summarise()` has grouped output by 'region'. You can override using the\n`.groups` argument.\n\nggarrange(\n  ggplot(temp, aes(x = region, y = area_km2, fill = factor(infrastructureIndex)))+\n    geom_bar(position = \"stack\", stat = \"identity\")+\n    guides(fill = \"none\")+\n    coord_flip()+\n    xlab(\"\")\n  ,\n  ggplot(temp, aes(x = region, y = area_km2, fill = factor(infrastructureIndex)))+\n    geom_bar(position = \"fill\", stat = \"identity\")+\n    guides(fill = guide_legend(\"HIF\"))+\n    coord_flip()+\n    ylab(\"Fraction of total area\")+\n    xlab(\"\")\n)\n\n\n\n\nStacked barplot showing the distribution of human impact factor across five regions in Norway.\n\n\n\n\nThis distribution looks reasonable. The relative proportions are similar in the five regions, but Østlandet and Sørlandet have more infrastructure in general.\nHere are the numbers behind the figure above.\n\ntemp$area_km2 <- round(temp$area_km2,0)\nDT::datatable(temp)"
  },
  {
    "objectID": "homogeneous_impact_areas.html#export",
    "href": "homogeneous_impact_areas.html#export",
    "title": "7  Homogeneous Impact Areas",
    "section": "7.5 Export",
    "text": "7.5 Export\nI will write this data to the NINA P server.\n\nsaveRDS(infra_agg_discrete_vect, \"P:/41201785_okologisk_tilstand_2022_2023/data/infrastrukturindeks/homogeneous_impact_areas.rds\")\n\n\nHIA_returned <- readRDS(\"P:/41201785_okologisk_tilstand_2022_2023/data/infrastrukturindeks/homogeneous_impact_areas.rds\")"
  },
  {
    "objectID": "alien_species.html#introduction",
    "href": "alien_species.html#introduction",
    "title": "4  Alien species",
    "section": "4.1 Introduction",
    "text": "4.1 Introduction\nThis indicator represent the the ecological on-site effect from alien species. Whilst the introduction of alien species is best considered a pressure variable, the relative abundance of alien species on a given location is seen here as a manifestation of this negative anthropogenic impact, and is therefore a valid condition indicator.\nA related variable has been used previously for alpine and forest ecosystems in Norway. These indicators were based on ANO, a national monitoring program, where alien species cover was estimated to the closest whole %. The upper and lower reference levels that was used back then was 0 or 100% of the species composition made up of alien species, respectively. The threshold value between good and reduced condition was defined as 5%. In this approach, the indicator represented the relative area with an absence of alien species. It is in a way the flip-side of alien species abundance. The latter was said to be a pressure variable, whilst the former reacts as direct and linear consequence of changes to this variable, and was therefore accepted as a condition indicator. We do not make this distinction here.\nThis time we are using the nature type mapping dataset which records the assumed effect of alien species, rather than a direct measure of abundance such as % cover. The recording scale is called R7 (Fig. @ref(fig:R7)) and is an ordinal scale which has a non-linear relationship with %cover recorded in ANO (Fig. @ref(fig:fremmedart-prosentVSinnslag)). In order to combine these two data sets, we must convert one of these scales to match the other.\nHere I base the indicator on the R7 scale, since this is, presumably, the bigger data set. I therefore convert %cover into R7 classes based on what I can interpret from Fig. @ref(fig:fremmedart-prosentVSinnslag).\nUpper reference value is then 1, and lower reference value is 7, on the R7 scale. For the threshold value I will set this to value 4 on the R7 scale. This is based on interpretation by the author and based of the definition of this value in Fig. @ref(fig:R7). Step 4 on the R7 scale is the step that, concordantly, best matches the 5% threshold in the old approach, as seen from Fig. @ref(fig:fremmedart-prosentVSinnslag).\n\nknitr::include_graphics(\"images/R7 scale.PNG\")\n\n\n\n\nThe R7 scale used when recording the effect of alien species in the nature type monitoring program\n\n\n\n\n\nknitr::include_graphics(\"images/fremmedart_prosentVSinnslag.PNG\")\n\n\n\n\nComparing the R7 scale (x axis) which is used in the nature type monitoring program with %cover (y-axis), which is how alien species is recorded in ANO. I am assuming the x axis is shifted downwards compared to the original R7 scale which range from 1 to 7, so that a value of 0 here equals an R7 value of 1. Cropped from Evju et al (2022).\n\n\n\n\nSince the nature type data is not sampled in a systematic or random way, we must take extra care not to over-extrapolate in space. We delineate homogeneous impact areas (HIA) based on four classes of increasing infrastructure intersected with municipality borders, and we say that if we have more than n data points than this field data is representative inside the entire HIA. In a related indicator we used the accounting areas to define the HIA (5 accounting areas in Norway), in addition to the infrastructure classes. For this indicator, we expect more gradients also inside accounting areas, and therefore we define HIAs based on municipalities. This means that there will be more missing data in our final indicator maps, since not all municipalities will have sufficient data points to estimate indicator values.\nWe then calculate an area weighted mean (and error) indicator value for each HIA, as long as there is more than n data points for a given combination of HIA and municipality.\nHere a general workflow for the calculation of the indicator.\n\nImport Nature type data data set (incl. GRUK) and ANO data set\nIdentify the relevant nature types and subset the data\nConvert ANO points to polygons\nCombine data sets\nScale the alien species variable based on reference values.\nDefine homogeneous impact areas (HIA) based on an infrastructure index and municipalities\nAggregate and spread indicator value across HIAs (and municipalities)\nConfirm relationship between infrastructure index and indicator values to justify the extrapolation\nTO DO: Prepare ecosystem delineation maps and us ethese to mask the extrapolated indicator maps\nSpatial aggregation of indicator values and uncertainties to accounting areas\nExport indicator maps and regional extrapolated maps"
  },
  {
    "objectID": "alien_species.html#about-the-underlying-data",
    "href": "alien_species.html#about-the-underlying-data",
    "title": "4  Alien species",
    "section": "4.2 About the underlying data",
    "text": "4.2 About the underlying data\nThe indicator uses a data set from a standardised field survey of nature types. You can read more about this data set from my preliminary analyses here. See also the official site of the Environment Agency. I also import a data set called ANO, which you can read about here.\n\n4.2.1 Representativity in time and space\nThe nature type mapping is not random and cannot be said to be area representative. The ANO data set however, is area representative. The data is from 2018 to present. The data from one field season usually becomes available early the following year.\n\n\n4.2.2 Original units\nThe variables are recorded on a unitless seven-step ordinal scale (Fig. @ref(fig:R7)) or a as a % cover of alien species.\n\n\n4.2.3 Temporal coverage\nThe data goes back to 2018. I therefore bulk all the data from 2018 to 2022 into one time step. I then use the mean date for the raw data, and define the variable as belonging to the year 2020 (read more here).\n\n\n4.2.4 Aditional comments about the dataset\nFor a run through of the nature type data set, see here."
  },
  {
    "objectID": "alien_species.html#ecosystem-characteristic",
    "href": "alien_species.html#ecosystem-characteristic",
    "title": "4  Alien species",
    "section": "4.3 Ecosystem characteristic",
    "text": "4.3 Ecosystem characteristic\n\n4.3.1 Norwegain standard\nThe indicator is tagged to the Økologisk egenskap called Funksjonelt viktige arter og strukturer (Functionally important species and structures). This emphasises the negaivte effect that alien species has on for example supressing or excluding native species. In some cases, alien species can also affect nutrient cycling or recruitment.\n\n\n4.3.2 UN standard\nThe indicator is tagged as a B1 Compositional state characteristics indicator."
  },
  {
    "objectID": "alien_species.html#collinearities-with-other-indicators",
    "href": "alien_species.html#collinearities-with-other-indicators",
    "title": "4  Alien species",
    "section": "4.4 Collinearities with other indicators",
    "text": "4.4 Collinearities with other indicators\nAlien species is not thought to exhibit collinearity with any other indicator at the present."
  },
  {
    "objectID": "alien_species.html#reference-condition-and-values",
    "href": "alien_species.html#reference-condition-and-values",
    "title": "4  Alien species",
    "section": "4.5 Reference condition and values",
    "text": "4.5 Reference condition and values\n\n4.5.1 Reference condition\nThe reference condition is one with minimal negative human impact. This is also true for semi-natural ecosystems. In a sense, the reference condition is pre 1800s, since alien species are defined as species established post 1800.\n\n\n4.5.2 Reference values, thresholds for defining good ecological condition, minimum and/or maximum values\n\nUpper = 1 (R7 scale), corresponding to 0% alien species\nThreshold = 4 (R7 scale), corresponding to about 5-30% alien species cover.\nLower = 7 (R7 scale), corresponding to 100% alien species cover.\n\nRead about the normalisation here."
  },
  {
    "objectID": "alien_species.html#uncertainties",
    "href": "alien_species.html#uncertainties",
    "title": "4  Alien species",
    "section": "4.6 Uncertainties",
    "text": "4.6 Uncertainties\nUncertainties/errors are estimated for aggregated indicator values by bootstrapping individual indicator values 1000 times and calculating a distribution of area weighted means. This uncertainty is different from the spatial variation which we could get more straight forward without bootstrapping. When aggregating a second time, from homogeneous impact areas to accounting areas, we assume a normal distribution around the indicator values, with the already mentioned errors, and sample n times from these and combine the resamples into an a new, area weighted, distribution. The errors for the accounting areas thus represents both the spatial variation, and the precision, of the indicator values within the accounting areas."
  },
  {
    "objectID": "alien_species.html#references",
    "href": "alien_species.html#references",
    "title": "4  Alien species",
    "section": "4.7 References",
    "text": "4.7 References\nNature type data\nANO\nEvju, M., Skrindo, A.B. & Solstad, H. (red.) 2022. Overvåking av åpen grunnlendt kalkmark 2021‒2024. Årsrapport 2022. NINA Rapport 2195. Norsk institutt for naturforskning."
  },
  {
    "objectID": "alien_species.html#analyses",
    "href": "alien_species.html#analyses",
    "title": "4  Alien species",
    "section": "4.8 Analyses",
    "text": "4.8 Analyses\n\n4.8.1 Data sets\n\n4.8.1.1 Nature type mapping\nThis indicator uses the data set Naturtyper etter Miljødirektoratets Instruks, which can be found here. See also here for a detailed description of the data set.\nWe also have a separate summary file where the nature types are manually mapped to the NiN variables and to the correct NiN-main types. We can use this to find the nature types of interest.\n\nnaturetypes_summary_import <- readRDS(\"data/naturetypes/natureType_summary.rds\")\n\nWe are only interested in a mapping units that include our target variables. The variable fremmedartsinnslag is coded as 7FA.\n\nmyVars <- '7FA'\n\n\nnaturetypes_summary <- naturetypes_summary_import %>%\n  rowwise() %>%\n  mutate(keepers = sum(c_across(\n    all_of(myVars))>0, na.rm=T)) %>%\n  filter(keepers >0) %>%\n  select(Nature_type, NiN_mainType, Year)\n\nThis deleted 30 nature types and left us with these 24 nature types where 7FA was recorded:\n\nDT::datatable(naturetypes_summary)\n\n\n\n\n\n\nImporting and sub-setting the main data file, fix duplicate hovedøkosystem, calculate area, split one column in two, make numeric, and select target variables:\n\nnaturetypes <- sf::st_read(dsn = path) %>%\n  filter(naturtype %in% naturetypes_summary$Nature_type) %>%\n  mutate(hovedøkosystem = case_match(hovedøkosystem,\n                                  \"naturligÅpneOmråderILavlandet\" ~ \"naturligÅpneOmråderUnderSkoggrensa\",\n                                  .default = hovedøkosystem),\n         area = st_area(.)) %>%\n  separate_rows(ninBeskrivelsesvariable, sep=\",\") %>%\n  separate(col = ninBeskrivelsesvariable,\n           into = c(\"NiN_variable_code\", \"NiN_variable_value\"),\n           sep = \"_\",\n           remove=F) %>%\n  mutate(NiN_variable_value = as.numeric(NiN_variable_value)) %>%\n  filter(NiN_variable_code %in% myVars)\n\nReading layer `Naturtyper_nin_0000_norge' from data source \n  `/data/R/GeoSpatialData/Habitats_biotopes/Norway_Miljodirektoratet_Naturtyper_nin/Original/Naturtyper_nin_0000_norge_25833_FILEGDB/Naturtyper_nin_0000_norge_25833_FILEGDB.gdb' \n  using driver `OpenFileGDB'\nSimple feature collection with 117427 features and 36 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -74953.52 ymin: 6448986 xmax: 1075081 ymax: 7921284\nProjected CRS: ETRS89 / UTM zone 33N\n\n\n\nggplot(data = naturetypes, aes(x = naturtype, fill = hovedøkosystem))+\n  geom_bar()+\n  coord_flip()+\n  theme_bw(base_size = 10)+\n  theme(legend.position = \"top\",\n        legend.title = element_blank(),\n        legend.direction = \"vertical\")+\n  guides(fill = \"none\")+\n  xlab(\"\")+\n  ylab(\"Number of localities\")+\n  facet_wrap(.~hovedøkosystem, ncol=1, scale=\"free\")\n\n\n\n\nAn overview of the naturetypes for which we will calculate the indicator.\n\n\n\n\nNote that there is a lot more data for semi-natural ecosystem compared to the other two.\nColumn names starting with a number is problematic, so adding a prefix\n\nnaturetypes$NiN_variable_code <- paste0(\"var_\", naturetypes$NiN_variable_code)\n\nRemoving NA’s\n\nnaturetypes <- naturetypes[!is.na(naturetypes$NiN_variable_value),]\n\nShift variable to start from 1 rather than from 0.\n\nnaturetypes$NiN_variable_value <- naturetypes$NiN_variable_value+1\n\n\nggplot(naturetypes, aes(x = NiN_variable_value))+\n  geom_histogram(fill=\"grey\",\n           colour = \"black\",\n           binwidth = 1)+\n  theme_bw(base_size = 12)+\n  labs(x = \"Alien species variable score\") +\n  facet_wrap(.~hovedøkosystem, scales=\"free_y\")\n\n\n\n\nAlien species variable scores in the nature type data set.\n\n\n\n\nIt appears most localities are in good condition, and most localities have no alien species at all.\n\n\n4.8.1.2 GRUK\nThis variable is also recorded in GRUK. The nature type data set I’m working on here includes this data already (presently only 2021 included). GRUK also records a related variable: % cover in 5m radii circles, which is much more detailed. This data is not published. In any case it is better to use the harmonized data set in our case.\nNOTE: I’m not sure, but I wonder if the 2021 GRUK data was a pilot project and that most GRUK data, and all future GRUK data, will not be included in this data set.\n\n\n4.8.1.3 ANO\nArealrepresentativ Naturovervåking (ANO) consist of 1000 systematically placed locations in Norway, each with 18 sample points. In each sample point a circle of 250 m2 is visualised, and the main ecosystem is recorded.\nThe %cover of alien vascular plant is estimated, independent on main ecosystem type. In contrast to the nature type data set, ANO only looks at vascular plants, and then also only the three strictest categories in the alien plant list (SE, HI, PH). It is therefore not completely unproblematic to combine these to data sets, but we will do so anyway. We expect plants to be the by far most common species group to influence the 7FA variable as well. And similarly, we expect the three strictest alien plant categories to contain the most aggressive species which will drive the 7FA variable more so than the other categories.\n\nano_eco <- c(\"vaatmark\", \"naturlig_apne\", \"semi_naturlig_mark\")\nano <- sf::st_read(paste0(pData, \"Naturovervaking_eksport.gdb\"),\n                   layer = \"ANO_SurveyPoint\") %>%\n  dplyr::filter(hovedoekosystem_punkt %in% ano_eco) %>%\n   mutate(hovedoekosystem_punkt = case_match(hovedoekosystem_punkt,\n                                       \"vaatmark\" ~ \"våtmark\",\n                                       \"naturlig_apne\" ~ \"naturligÅpneOmråderUnderSkoggrensa\",\n                                       \"semi_naturlig_mark\" ~ \"semi-naturligMark\",\n                                       .default = hovedoekosystem_punkt))\n\nReading layer `ANO_SurveyPoint' from data source \n  `/data/P-Prosjekter2/41201785_okologisk_tilstand_2022_2023/data/Naturovervaking_eksport.gdb' \n  using driver `OpenFileGDB'\nSimple feature collection with 8974 features and 71 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -51950 ymin: 6467050 xmax: 1094950 ymax: 7923950\nProjected CRS: ETRS89 / UTM zone 33N\n\n\n\ntable(ano$aar)\n\n\n2019 2021 \n 215  887 \n\n\nThis data set only contains data from year 2019 and 2021. We need to update this data set later. It is not clear why there is no data from 2020.\nEach point/row here is 250 square meters. The data also contains information about how big a proportion of this area is made up of the dominant main ecosystem. However, there are 215 NA’s here, which is 20% of the data.\nIt appears the proportion of each circle that is made up of the dominant ecosystem was only recorded after year 2019. In fact, the main ecosystem was not recorded at all in 2019:\n\ntable(ano$hovedtype_250m2, ano$aar)\n\n                            \n                             2019 2021\n  Åpen flomfastmark             0    1\n  Åpen grunnlendt mark          0   90\n  Åpen jordvannsmyr             0  417\n  Boreal hei                    0   81\n  Fjellhei leside og tundra     0    5\n  Grøftet torvmark              0    5\n  Helofytt-ferskvannssump       0    3\n  Historisk skredmark           0    3\n  Isinnfrysingsmark             0    1\n  Kaldkilde                     0    3\n  Kystlynghei                   0   26\n  Løs sterkt endret fastmark    0    1\n  Myr- og sumpskogsmark         0   51\n  Nakent berg                   0   35\n  Nedbørsmyr                    0   53\n  Rasmark                       0   23\n  Rasmarkhei og -eng            0    3\n  Semi-naturlig eng             0   44\n  Semi-naturlig myr             0   14\n  Semi-naturlig våteng          0    2\n  Skogsmark                     0    3\n  Strandberg                    0    5\n  Strandeng                     0    2\n  Strandsumpskogsmark           0    2\n  Våtsnøleie og snøleiekilde    0    6\n\n\nI can remove the NA’s, and thus the 2019 data.\n\nAll of 2019 ANO data is excluded because of missing information\n\n\nano <- ano[!is.na(ano$andel_hovedoekosystem_punkt),]\n\nLet’s look at the variation in the recorded proportion of ecosystem cover\n\npar(mar=c(5,6,4,2))\nplot(ano$andel_hovedoekosystem_punkt[order(ano$andel_hovedoekosystem_punkt)],\n     ylab=\"Percentage of the 250 m2 area\\ncovered by the main ecosystem\")\n\n\n\n\nDistribution of the ANO variable andel_hovedoekosystem_punkt.\n\n\n\n\nThe zero in there is an obvious mistake. Removing it:\n\nano <- ano[ano$andel_hovedoekosystem_punkt>20,]\n\nHere’s another plot of the distribution of the same variable:\n\nggplot(ano, aes(x = andel_hovedoekosystem_punkt))+\n         geom_histogram(fill = \"grey\",\n                        colour=\"black\",\n                        binwidth = 1)+\n  theme_bw(base_size = 12)+\n  xlab(\"Percentage cover of the main ecosystem\\n in the 250m2 circle\")+\n  scale_x_continuous(limits = c(0,101),\n                     breaks = seq(0,100,10))\n\n\n\n\nPercentage cover of the main ecosystem in the 250m2 circle\n\n\n\n\nWe can see that people tend to record the variable in steps of 5%, and that most sample points are 100% belonging to the same main ecosystem.\nWe want to use area weighting in this indicator, so we can use this percentage cover data to calculate the area. Note that both data sets use m2 as area units.\n\nano$area <- (ano$andel_hovedoekosystem_punkt/100)*250\n\nLet’s now look at the distribution of the variable. It is coded as fa_total_dekning. First, there are 73 NA’s in this column which we can remove.\n\nano <- ano[!is.na(ano$fa_total_dekning),]\n\nLet us plot the distribution of values.\n\nggplot(ano, aes(x = fa_total_dekning))+\n  geom_histogram(fill=\"grey\",\n           colour = \"black\",\n           binwidth = 1)+\n  theme_bw(base_size = 12)+\n  labs(x = \"% cover alien vascular plants\") +\n  facet_wrap(.~hovedoekosystem_punkt, scales=\"free_y\")\n\n\n\n\nDistribution of %cover of alien plants variable in the ANO data set\n\n\n\n\nThe ANO localities seemingly have less alien plants in them than the nature type localities. This can be du to sampling biases in the latter.\nNow I will convert these %cover values into 7FA classes. This is a critical step, since there is no one-to-one mapping here, but rather there is considerable overlap, as can be seen in Fig. @ref(fig:fremmedart-prosentVSinnslag).\n\nano <- ano %>%\n  mutate(var_7FA = case_when(\n             fa_total_dekning>90 ~ 7,\n             fa_total_dekning>25 ~ 6,\n             fa_total_dekning>10 ~ 5,\n             fa_total_dekning>5 ~ 4,\n             fa_total_dekning>2 ~ 3,\n             fa_total_dekning>1 ~ 2,\n             fa_total_dekning<1 ~ 1))\n\n\nggplot(ano, aes(x = var_7FA))+\n  geom_histogram(fill=\"grey\",\n           colour = \"black\",\n           binwidth = 1)+\n  theme_bw(base_size = 12)+\n  labs(x = \"% cover alien vascular plants\\n converted to the R7 scale\") +\n  facet_wrap(.~hovedoekosystem_punkt, scales=\"free_y\")\n\nWarning: Removed 6 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nDistribution of R7 values in the ANO data set\n\n\n\n\n\n4.8.1.3.1 Combine Naturtype data and ANO\nWe need to combine the nature type data set with the ANO data set. I will add a column origin to show where the data comes from. I will also add a column with the main ecosystem.\n\nano$origin <- \"ANO\"\nnaturetypes$origin <- \"Nature type mapping\"\nano$hovedøkosystem <- ano$hovedoekosystem_punkt\nano$kartleggingsår <- ano$aar\n\nFix class\n\nnaturetypes$kartleggingsår <- as.numeric(naturetypes$kartleggingsår)\nnaturetypes$area <- units::drop_units(naturetypes$area)\n\nI use dplyr::select to reduce the number of columns to keep things a bit more tidy.\n\nalien_data <- dplyr::bind_rows(select(ano,\n                                  GlobalID,\n                                  origin,\n                                  kartleggingsår,\n                                  hovedøkosystem,\n                                  area,\n                                  var_7FA,\n                                  SHAPE), \n                           select(naturetypes,\n                                  identifikasjon_lokalId,\n                                  origin,\n                                  hovedøkosystem,\n                                  kartleggingsår,\n                                  area,\n                                  var_7FA = NiN_variable_value,\n                                  SHAPE))\n\n\n4.8.1.3.1.1 Points to polygons\nThe ANO data is point data and the nature type data is multipolygon:\n\nunique(st_geometry_type(alien_data))\n\n[1] POINT        MULTIPOLYGON\n18 Levels: GEOMETRY POINT LINESTRING POLYGON MULTIPOINT ... TRIANGLE\n\n\nBecause later we will rasterize these data, we will convert the points to polygons. I use the area column to calculate a radii that gives that area.\n\nalien_data_points <- alien_data %>%\n  mutate(g_type = st_geometry_type(.)) %>%\n  filter(g_type ==\"POINT\") %>%\n  st_buffer(sqrt(alien_data$area/pi))\n\nChecking now that the new polygons have the area corresponding to the proportion of the point that was part of the same main ecosystem:\n\nalien_data_points$area2 <- st_area(alien_data_points)\nplot(alien_data_points$area, alien_data_points$area2,\n     xlab = \"Target area\",\n     ylab = \"Area of the new polygons\")\nabline(0,1)\n\n\n\n\nChecking that the area of the new polygons fall in line with the proportion of each point which is part of the main ecosystem.\n\n\n\n\nThe area calculation seems to have worked fine. Checking that the new data set contains only polygons.\n\nalien_data_polygons <- alien_data %>%\n  mutate(g_type = st_geometry_type(.)) %>%\n  filter(g_type !=\"POINT\")\n\nalien_data <- bind_rows(alien_data_points, alien_data_polygons)\n\nunique(st_geometry_type(alien_data))\n\n[1] POLYGON      MULTIPOLYGON\n18 Levels: GEOMETRY POINT LINESTRING POLYGON MULTIPOINT ... TRIANGLE\n\n\nOk.\n\n\n\n\n4.8.1.4 Distribution of 7FA scores\n\ntemp <- as.data.frame(table(alien_data$var_7FA))\nggplot(temp, aes(x = Var1,\n                 y = Freq))+\n  geom_bar(stat=\"identity\",\n           fill=\"grey\",\n           colour = \"black\")+\n  theme_bw(base_size = 12)+\n  labs(x = \"7FA score\",\n       y = \"Number of localities\")\n\n\n\n\n7FA (alien species) scores (ANO Naturetype (and GRUK) data combined).\n\n\n\n\nLet’s see the proportion of data points (not area) originating from each data set\n\ntemp <- as.data.frame(table(alien_data$origin))\n\nggplot(temp, aes(x = Var1,\n                 y = Freq))+\n  geom_bar(stat=\"identity\",\n           fill=\"grey\",\n           colour = \"black\")+\n  theme_bw(base_size = 12)+\n  labs(x = \"Data origin\",\n       y = \"Number of localities\")\n\n\n\n\nBarplot showing the contribution (number of localities) of different data sets to the alien species indicator.\n\n\n\n\nSo the ANO data is not very important here, but it can become more important in the future so good to have them included in the workflow.\n\n\n4.8.1.5 Outline of Norway and regions\nThese layers are used to crop out marine areas, and to define accounting areas, respectively.\n\noutline <- sf::read_sf(\"data/outlineOfNorway_EPSG25833.shp\")\n\n\nregions <- sf::read_sf(\"data/regions.shp\", options = \"ENCODING=UTF8\")\nunique(regions$region)\n\n[1] \"Nord-Norge\" \"Midt-Norge\" \"Østlandet\"  \"Vestlandet\" \"Sørlandet\" \n\n\nMunicipalities\n\npath1 <- ifelse(dir == \"C:\", \n               \"R:/\",\n               \"/data/R/\")\n\npath <- paste0(path1, \"GeoSpatialData/AdministrativeUnits/Norway_AdministrativeUnits/Original/Norway_Municipalities/Basisdata_0000_Norge_25833_Kommuner_FGDB.gdb\")\n\n# find the correct layer\n#st_layers(path)\nmuni <- sf::read_sf(path, options = \"ENCODING=UTF8\", layer = \"kommune\")\n\nThere are some multi-surfaces in here that I will convert to multi-polygons before plotting.\n\nmuni <- st_cast(muni, \"MULTIPOLYGON\")\ntm_shape(muni)+\n  tm_polygons(col=\"kommunenummer\")+\n  tm_layout(legend.outside = T)\n\n\n\n\nMunicipalities in Norway.\n\n\n\n\n\n\n\n4.8.2 Scaled indicator values\nI can scale the indicator for each polygon, or I can chose to aggregate them first. If the scaled value is representative and precise at the polygon level, then I could scale at that level. I think they are.\nHowever, the combined surveyed area is a very small fraction of the total area of Norway, so that only producing indicator values for the mapped areas leaves the indicator without much value for regional assessments. But we cannot simply do an area weighting of the polygons in each region. This is because we expect considerable sampling bias and we can’t assume that the polygons are representative far outside of the mapped area. But perhaps we can assume them to be representative inside homogeneous ecological areas, or Homoegeneous Impact Areas (HIAs). That’s where the infrastructure index comes in. Here’s the plan:\n\nnormalise the indicators at the polygon level.\ntake a simplified infrastructure index (vector data) and intersect this with municipality borders to produce a map of homogeneous impact areas (HIAs).\nextract the corresponding indicator values that intersect with a given HIA, and extrapolate the area weighted mean of those values to the entire HIA. Errors are calculated from bootstrapping.\nTake the new area weighted indicator values for the HIAs, rasterize it, and mask these with ecosystem occurrences. The errors are the same as for the HIAs.\ncalculate an indicator value for a region (accounting area) by doing a weighted average based of the relative area of ecosystem occurrences. Errors should be carried somehow, perhaps via weighted resampling.\n\n\n4.8.2.1 Scaled variable\nI will use the same reference levels/values for all of Norway:\n\nlow <- 1\nhigh <- 7\nthreshold <- 4\n\n\neaTools::ea_normalise(data = alien_data,\n                      vector = \"var_7FA\",\n                      upper_reference_level = high,\n                      lower_reference_level = low,\n                      break_point = threshold,\n                      plot=T,\n                      reverse = T\n                      )\n\nWarning: Removed 6 rows containing missing values (`geom_point()`).\n\n\n\n\n\nPerforming a linear break-point type normalisation of the alien species variable.\n\n\n\n\nThere is no point yet making this a time series, and I will assign all the indicator value to the average year of the data.\n\nmean(alien_data$kartleggingsår)\n\n[1] 2020.12\n\n\nAssigning the indicator to year 2020.\n\nalien_data$i_2020 <- eaTools::ea_normalise(data = alien_data,\n                      vector = \"var_7FA\",\n                      upper_reference_level = high,\n                      lower_reference_level = low,\n                      break_point = threshold,\n                      reverse = T\n                      )\n\n\n\n\n4.8.3 Homogeneous impact areas\nI want to use the Homogeneous Impact Areas (HIA) to define smaller regions into which I can extrapolate the indicator values. This data is generated by discretizing the Norwegian Infrastructure Index. I refer to the ordinal values of the four HIA classes as their Human Impact Factor (HIF). This is just to keep the approach separate from the Norwegian Infrastructure Index.\n\nHIA <- readRDS(paste0(pData, \"infrastrukturindeks/homogeneous_impact_areas.rds\"))\n\nI want to check that HIF is in fact a good predictor for alien species.\nI also want to split these four HIA classes based on municipality. To do this I need the two layers to have the same CRS.\n\nst_crs(HIA) == st_crs(muni)\n\n[1] TRUE\n\n\nThen we get the intersections (unique combinations)\n\nHIA_muni <- eaTools::ea_homogeneous_area(HIA,\n                             muni,\n                             keep1 = \"infrastructureIndex\",\n                             keep2 = \"kommunenummer\")\nsaveRDS(HIA_muni, \"P:/41201785_okologisk_tilstand_2022_2023/data/cache/HIA_muni.rds\")\n\nCreate a new column by crossing municipality number and HIF\n\nHIA_muni <- HIA_muni %>%\n  mutate(muni_HIF = paste(\"ID\", kommunenummer, infrastructureIndex, sep=\"_\"))\n\nHere is a view of the data zooming in on Trondheim\n\nmyBB <- st_bbox(c(xmin=260520.12, xmax = 278587.56,\n                ymin = 7032142.5, ymax = 7045245.27),\n                crs = st_crs(HIA_muni))\n\nCropping the raster to the bbox\n\nHIA_trd <- sf::st_crop(HIA_muni, myBB)\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n\nGet map of major roads, for context\n\nhw_utm <- readRDS(\"data/cache/highways_trondheim.rds\")\n\n\n(HIA_trd <- tm_shape(HIA_trd)+\n  tm_polygons(col = \"infrastructureIndex\",\n    title=\"Infrastructure index\\n(modified 4-step scale)\",\n    palette = \"-viridis\",\n    style=\"cat\")+\n  tm_layout(legend.outside = T)+\n  tm_shape(hw_utm)+\n  tm_lines(col=\"red\")+\n  tm_shape(outline)+\n  tm_borders(col = \"black\", lwd=2))\n\n\n\n\nA closer look at the HIA designation over Trondheim\n\n\n\n\nSee Fig. @ref(fig:HIF-region) for a closer look at the distribution of HIA classes across Norway.\n\n4.8.3.1 Validate\nI now have 1350 HIAs (for each main ecosystem) that I will, given there is data, extrapolate indicator values over. But first I want to validate the assumption that the HIF explains a considerable portion of the variation in the indicator values.\nI will subset the alien_data into the three ecosystems.\n\n#make geometries valid \nalien_data <- st_make_valid(alien_data)\n\n#subset\nwetlands <- alien_data[alien_data$hovedøkosystem == \"våtmark\",]\nseminat <- alien_data[alien_data$hovedøkosystem == \"semi-naturligMark\",]\nnatOpen <- alien_data[alien_data$hovedøkosystem == \"naturligÅpneOmråderUnderSkoggrensa\",]\n\nCreating some summary statistics.\n\nwetland_stats <- ea_spread(indicator_data = wetlands,\n          indicator = i_2020,\n          regions = HIA_muni,\n          groups = muni_HIF,\n          summarise = TRUE)\n\nseminat_stats <- ea_spread(indicator_data = seminat,\n          indicator = i_2020,\n          regions = HIA_muni,\n          groups = muni_HIF,\n          summarise = TRUE)\n\nnatOpen_stats <- ea_spread(indicator_data = natOpen,\n          indicator = i_2020,\n          regions = HIA_muni,\n          groups = muni_HIF,\n          summarise = TRUE)\n\nwetland_stats <- wetland_stats %>%\n  add_column(eco = \"wetland\")\n\nseminat_stats <- seminat_stats %>%\n  add_column(eco = \"semi-natural\")\n\nnatOpen_stats <- natOpen_stats %>%\n  add_column(eco = \"Naturally-open\")\n\nall_stats <- rbind(wetland_stats,\n                   seminat_stats,\n                   natOpen_stats)\nall_stats <- all_stats %>%\n  separate(muni_HIF,\n           into = c(\"tempLink\", \"municipalityNumber\", \"HIF\"),\n           sep = \"_\")\n\n#saveRDS(all_stats, \"/data/P-Prosjekter2/41201785_okologisk_tilstand_2022_2023/data/cache/all_stats_alienSpecies.rds\")\nsaveRDS(all_stats, \"P:/41201785_okologisk_tilstand_2022_2023/data/cache/all_stats_alienSpecies.rds\")\n\nWe have data from 277 out of 363 municipalities. This figure shows how many municipalities we have at least one data point for, specific for each human impact factor level:\n\nall_stats %>%\n  group_by(HIF, eco) %>%\n  summarise(n = n()) %>%\n  ggplot()+\n  geom_bar(aes(x = HIF, y = n), stat =\"identity\")+\n  theme_bw()+\n  ylab(\"Number of municipalities\")+\n  facet_wrap(.~eco)\n\n`summarise()` has grouped output by 'HIF'. You can override using the `.groups`\nargument.\n\n\n\n\n\nNumber of municipalities we have at least one data point for, specific for each human impact factor level.\n\n\n\n\nIf we say that we need 20 data points for each HIA and municipality combination in order to extrapolate to the entire HIA for that municipality, we get much less to work with:\n\nall_stats %>%\n  filter(n>20) %>%\n  group_by(HIF, eco) %>%\n  summarise(n = n()) %>%\n  ggplot()+\n  geom_bar(aes(x = HIF, y = n), stat =\"identity\")+\n  theme_bw()+\n  ylab(\"Number of municipalities\")+\n  facet_wrap(.~eco)\n\n`summarise()` has grouped output by 'HIF'. You can override using the `.groups`\nargument.\n\n\n\n\n\nNumber of municipalities we have at least 20 data points for, specific for each human impact factor level.\n\n\n\n\n\nall_stats %>%\n  filter(n > 20) %>%\n  ggplot(aes(x = HIF, y = w_mean))+\n  geom_point(size=2, position = position_dodge2(.1))+\n  geom_violin(alpha=0)+\n  theme_bw()+\n  labs(x = \"Human impact factor\",\n       y = \"Indicator value (area weighted means)\")\n\n\n\n\nIndicator-pressure relationship across all ecosystems.\n\n\n\n\nThere is a trend here, but not very strong perhaps.\nHere is a similar figure, looking at the relative frequency of indicator level of polygons and within each HIA.\n\ncorrCheck <- st_intersection(alien_data, HIA)\nsaveRDS(corrCheck, paste0(pData, \"cache/corrCheck_alienSpecies.rds\")\n\n\nggplot(corrCheck, aes(x = factor(infrastructureIndex), fill = factor(round(i_2020,2))))+\n  geom_bar(position=\"fill\")+\n  theme_bw(base_size = 12)+\n  guides(fill = guide_legend(\"Alien species indicator\"))+\n  ylab(\"Fraction of data points\")+\n  xlab(\"HIF\")+\n  scale_fill_brewer(palette = \"RdYlGn\")+\n  facet_wrap(.~hovedøkosystem)\n\n\n\n\nRelative frequency plot showing the distribution of polygons with different indicator values.\n\n\n\n\nThe figure above I think supports the indicator-pressure relationship and justifies using the HIA x municipality intersections as local reference areas.\nLet us look at the effect of sample size on the indicator uncertainty.\n\nall_stats %>%\n  filter(n > 5) %>%\n  ggplot(aes(x = n, y = sd))+\n  geom_point(size=2, position = position_dodge2(.1))+\n  theme_bw()+\n    facet_wrap(.~eco, scales=\"free\")\n\n\n\n\nSample size against indicator uncertainty.\n\n\n\n\nThis shows that the uncertainty is really inflated with sample sizes less than about 50-100.\n\nDT::datatable(all_stats) %>%\n  formatRound(columns=3:8, digits=2)\n\n\n\n\nSummary statistics for the alien species indicator.\n\n\n\n\n\n4.8.4 Aggregate and spread (extrapolate)\nI now want to find the mean indicator value for each HIA (i.e. to aggregate) and to spread these out spatially to the entire HIA (i.e. to extrapolate).\nI want to add a threshold so that we don’t end up over extrapolating based on too few data points. I will use 20 data points as a minimum.\n\nwetland_alien_extr <- ea_spread(indicator_data = wetlands,\n                         indicator = i_2020,\n                         regions = HIA_muni,\n                         groups = muni_HIF,\n                         threshold = 20)\n\nseminat_alien_extr <- ea_spread(indicator_data = seminat,\n                         indicator = i_2020,\n                         regions = HIA_muni,\n                         groups = muni_HIF,\n                         threshold = 20)\n\nnatOpen_alien_extr <- ea_spread(indicator_data = natOpen,\n                         indicator = i_2020,\n                         regions = HIA_muni,\n                         groups = muni_HIF,\n                         threshold = 20)\n\nIt’s easier to see what’s happening if we zoom in a bit. I will look more closely at three example municipalities:\nTrondheim (municipality nr 5001), Nordre Follo (3020) and Målselv (5418).\n\nwetland_alien_extr <- wetland_alien_extr %>%\n  separate(ID,\n           into = c(\"ID\", \"municipalityNumber\", \"HIF\"),\n           sep = \"_\") %>%\n  add_column(eco = \"wetlands\")\n\nseminat_alien_extr <- seminat_alien_extr %>%\n  separate(ID,\n           into = c(\"ID\", \"municipalityNumber\", \"HIF\"),\n           sep = \"_\") %>%\n  add_column(eco = \"semi_natural\")\n\nnatOpen_alien_extr <- natOpen_alien_extr %>%\n  separate(ID,\n           into = c(\"ID\", \"municipalityNumber\", \"HIF\"),\n           sep = \"_\") %>%\n  add_column(eco = \"naturally_open\")\n\nalien_extr <- rbind(\n  wetland_alien_extr,\n  seminat_alien_extr,\n  natOpen_alien_extr\n)\n\n\nalien_extr_trd_nf <- alien_extr %>%\n  filter(municipalityNumber %in% c(\"5001\", \"3020\", \"5418\"))\n\n\nmyCol <- \"RdYlGn\"\n\ntmap_arrange(\ntm_shape(alien_extr_trd_nf)+\n  tm_polygons(col = \"w_mean\",\n    title=\"Alien species indicator\",\n    palette = myCol,\n     style=\"fixed\",\n    breaks = seq(0,1,.1))+\n  tm_layout(legend.outside = T)+\n  tm_facets(by=c(\"eco\", \"municipalityNumber\"))\n,\ntm_shape(alien_extr_trd_nf)+\n  tm_polygons(col = \"HIF\",\n    title=\"Human impact factor\",\n    palette = \"-viridis\",\n    style=\"cont\",\n    breaks = c(0,1))+\n  tm_layout(legend.outside = T)+\n  tm_facets(by=c(\"municipalityNumber\"))\n,\nncol=1,\nheights = c(1,0.3))\n\n\n\n\nAlien species indicator extrapolated over Nordre Follo (3020), Trondheim (5001) and Målselv (5418). Note that the maps are not masked by ecosystem type, so the three ecosystem specific indicators are overlaping. The bottom row shows the location of the four human impact sones.\n\n\n\n\nFigure @ref(fig:extrapolated-alien) again indicates that this indicator will have a lot of missing data (see also here). For Nordre Follo and Trondheim for example, we do not have any indicator values tied to naturally open or wetland ecosystems, and for semi natural ecosystems we only have data for HIF class 2. This is, however, still a lot better than discarding the entire data set due to issues related to area representativity. The amount of missing data in the indicator maps is closely tied to the chosen threshold value for how many data points we must have in order to calculate an (area weighted) mean indicator value. We have used 20 as the threshold here. For Målselv (far right column), we ended up having enough data for wetlands in HIF class 0, and since most of the municipality is in this HIF class we get a lot of indicator coverage.\nThe following table contains the data values underlying Figure @ref(fig:extrapolated-alien), including HIAs with <20 data points.\n\nall_stats %>%\n  filter(municipalityNumber %in% c(\"5001\", \"3020\", \"5418\")) %>%\n  arrange(municipalityNumber, eco, HIF) %>%\n  DT::datatable()%>%\n  formatRound(columns=3:8, digits=2)\n\n\n\n\nSummary statistics for three example municipalities.\n\n\nNote that we can also show the uncertainties on maps:\n\ntm_shape(alien_extr_trd_nf[alien_extr_trd_nf$eco==\"semi_natural\",])+\n  tm_polygons(col = \"sd\",\n    title=\"SD(alien\\nspecies indicator)\",\n    palette = \"-viridis\"\n     )+\n  tm_layout(legend.outside = T)+\n  tm_facets(by=\"municipalityNumber\")\n\n\n\n\nMap showing the uncertainties (spatial variation) around the indicator values for alien species in three example municipalities for Semi-natural ecosystems.\n\n\n\n\n\n\n4.8.5 Exploring the indicator values\nMost HIAs have good condition:\n\nalien_extr %>%\n  filter(!is.na(w_mean)) %>%\n  ggplot()+\n  geom_histogram(aes(x = w_mean))+\n  theme_bw()+\n  labs(x = \"Area weighted indicator value\",\n       y = \"Number of HIAs with >20 data points\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nNumber of HIAs with >20 data points (sum of all three ecosystems)\n\n\n\n\n\n4.8.5.1 Data coverage\nLet’s see how big proportion of Norway we ended up having data for. Ideally I would do this after masking the indicator maps with ecosystem delineations, but I can also get a good feel for the data coverage like this as well.\nThe area of Norway is\n\n(total_area <- st_area(outline))\n\n325694265348 [m^2]\n\n\nAnd here is the total and relative area of the indicator maps\n\nalien_extr %>%\n  filter(!is.na(w_mean)) %>%\n  mutate(m2 = st_area(.)) %>%\n  group_by(eco) %>%\n  summarise(sum_area = sum(m2)) %>%\n  add_column(total_area = total_area) %>%\n  mutate(relative_area = units::drop_units(sum_area/total_area)) %>%\n  ggplot()+\n  geom_bar(aes(x = eco, y = relative_area),\n           stat = \"identity\")+\n  labs(x = \"Ecosystem\", y = \"Relative indicator data coverage\")+\n  theme_bw()\n\n\n\n\nRelative area cover of the indicator maps for the alien species indicator (i.e. value 1 means that all HIAs had > 20 data points, and 0.2 means 20% of them did). If assuming the ecosystems are equally common where they are mapped and where they are not, this measure of data coverage is representative of the real indicator coverage after masking the maps with ecosystem delineations.\n\n\n\n\nFigure @ref(fig:relative-area) shows us that this indicator will provide indicator values for about 20% of the semi-natural ecosystem, and considerably less for the other two ecosystems. The data coverage is very sensitive to the threshold for minimum data points, set to >20 in this case. Also, with more nature type data accumulating over time, the data coverage will increase. Therefore I think this indicator is worth while, and that this is considerably better than the alternative to discard the entire data set.\n\n\n4.8.5.2 Effect of latitude\nAlien species tend to invade from the south. Let us see if there is an effect of latitude.\nExtracting x and y coordinates\n\ntemp <- alien_extr %>%\n  filter(!is.na(w_mean)) %>%\n  st_centroid() %>%\n  st_coordinates()\n\ntemp2 <- alien_extr %>%\n  filter(!is.na(w_mean))  %>%\n  cbind(temp)\n\n\ntemp2 %>%\n  ggplot(aes(x = X, y = w_mean))+\n  geom_point()+\n  theme_bw()+\n  geom_smooth(linewidth=2,\n              method=\"loess\",\n              span=0.75)+\n  labs(x = \"Latitude (UTM with offset)\",\n       y = \"Alien species indicator value\\n(area weighted)\")+\n  facet_wrap(~eco)\n\n\n\n\nEffect of latitude on the alien species indicator values. The blue line is a loess smoother (span=0.75).\n\n\n\n\nThere is a quite clear association here between latitude and the on-site effect of alien species."
  },
  {
    "objectID": "alien_species.html#next-steps",
    "href": "alien_species.html#next-steps",
    "title": "4  Alien species",
    "section": "4.9 Next steps",
    "text": "4.9 Next steps\nThe next steps now are to\n\nPrepare ecosystem delineation maps in EPSG:25833 and perfectly aligned to a master grid\nRasterize the extrapolated indicator map, using the ET map as a template\nand mask it using the perfectly aligned ET map.\nThen, look at [Median Summer Temperature] for how to aggregate spatially to accounting areas (regions)\n\nThis workflow should be synchronized with the slitasje indicator. I will attempt a little proof of concept below."
  },
  {
    "objectID": "alien_species.html#masking-example",
    "href": "alien_species.html#masking-example",
    "title": "4  Alien species",
    "section": "4.10 Masking with an ecosystem delineation - example",
    "text": "4.10 Masking with an ecosystem delineation - example\nLet’s try steps 2 and 3 on a reduced data set. I’ll work with wetlands in Gran municipality.\n\ngran <- wetland_alien_extr %>%\n  filter(municipalityNumber == \"3446\")\n\n\ntm_shape(gran)+\n  tm_polygons(col = \"w_mean\",\n    title=\"Alien species indicator - wetlands\",\n    palette = myCol,\n     style=\"fixed\",\n    breaks = seq(0,1,.1))+\n  tm_layout(legend.outside = T,\n            title = \"Gran municipality\")\n\n\n\n\nAlien species indicator over wetlands in Gran municipality.\n\n\n\n\nThen I can import and crop the ecosystem delineation map.\n\nfile <- \"P:/41201785_okologisk_tilstand_2022_2023/data/Myrmodell/myrmodell90pros.tif\"\nEDM <- stars::read_stars(file, proxy=F)\n\nThe EDM is in UTM32 when we actually want to have it in UTM33. But transforming it takes too long, so I will transform the indicator map instead.\n\ngran <- st_transform(gran, st_crs(EDM))\n\n\nmire_gran <- st_crop(EDM, gran)\nsaveRDS(mire_gran, paste0(pData, \"cache/mire_gran.rds\"))\n\n\nggplot()+\n  geom_stars(data = st_downsample(mire_gran, 10))\n\n\n\n\nWetlands in Gran municipality\n\n\n\n\nThen I rasterize the indicator map to match the EDM. This takes a while, even for just one municipality. I’m not sure this would work for the entire country.\n\ngran_rast <- st_rasterize(gran, template = mire_gran)  \nsaveRDS(gran_rast, paste0(pData, \"cache/gran_rast.rds\"))\n\n\ngran_outline <- muni %>%\n  filter(kommunenummer == \"3446\")\n\n\ntm_shape(st_downsample(gran_rast, 10))+\n  tm_raster(col=\"w_mean\")+\n  tm_shape(gran_outline)+\n  tm_borders(col=\"red\")\n\n\n\n\nIndictor values (alien species, extrapolated and area weighted values) in Gran municipality. Note that the pixelation is very small (10 x 10 m), and that the larger squares are remnants from the HIA map which was 1 x 1 km resolution.\n\n\n\n\nThen i mask to remove areas that are not actually watlands.\n\ngran_rast_masked <- gran_rast\ngran_rast_masked[mire_gran == 0] <- NA\n\n\ntm_shape(st_downsample(gran_rast_masked, 10))+\n  tm_raster(col=\"w_mean\",\n            palette = \"red\")+\n  tm_shape(gran_outline)+\n  tm_borders(col=\"red\")\n\n\n\n\nStratified, area weighted indictor values (alien species) in Gran municipality masked by a wetland ecosystem delimination map.\n\n\n\n\nFrom here it is easy to get zonal statistics using exactextratr. If I have this kind of map for all of Norway I can get the mean value for the regions (defined via a polygon set) and it will of course be area weighted (but no weight given to ecosystem occurences that don’t have indicator values)."
  },
  {
    "objectID": "scalingFunctions.html#linear-with-a-natural-zero",
    "href": "scalingFunctions.html#linear-with-a-natural-zero",
    "title": "6  Scaling functions",
    "section": "6.1 Linear, with a natural zero",
    "text": "6.1 Linear, with a natural zero\nWe can scale our variable linearly, saying that all values above 12 represents ‘perfect’ condition. We also assume that the value zero is the worst possible condition for this variable. To do this we divide by the reference value, and truncate values above it.\n\ndat$indicator1 <- dat$variable1/dat$referenceHigh1\ndat$indicator1[dat$indicator1>1] <- 1\n\ndat$indicator2 <- dat$variable2/dat$referenceHigh2\ndat$indicator2[dat$indicator2>1] <- 1\n\n\ntemp <- melt(setDT(dat),\n             measure.vars = c(\"indicator1\", \"indicator2\"))\n\n\nggplot(dat)+\n  geom_point(\n    aes(x = variable1, y = indicator1, fill = indicator1),\n             colour = myColour,\n             size   = mySize,\n             alpha  = myAlpha,\n             shape  = myShape)+\n  geom_vline(xintercept = dat$referenceHigh1[1],\n             linetype = \"dashed\",\n             size =2)+\n  \n  geom_point(aes(x = variable2, y = indicator2, fill = indicator2),\n             colour = myColour,\n             size   = mySize,\n             alpha  = myAlpha,\n             shape  = myShape)+\n  geom_vline(xintercept = dat$referenceHigh2,\n             linetype = \"dashed\",\n             size =2)+\n  ylab(\"Indicator values\")+\n  xlab(\"Variable values\")+\n  \n  scale_fill_gradient(\"Indicator values\", low = low, high = high)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nTo reverse what is good and what is bad condition: change the sign and add one.\n\nggplot(dat)+\n  geom_point(\n    aes(x = variable1, y = indicator1*(-1)+1, fill = indicator1*(-1)+1),\n             colour = myColour,\n             size   = mySize,\n             alpha  = myAlpha,\n             shape  = myShape)+\n  geom_vline(xintercept = dat$referenceHigh1[1],\n             linetype = \"dashed\",\n             size =2)+\n  \n  ylab(\"Indicator values\")+\n  xlab(\"Variable values\")+\n  \n  scale_fill_gradient(\"Indicator values\", low = low, high = high)\n\n\n\n\nThe two indicators become more comparable now that they are normalised. At least this is true around the reference value. But perhaps a variable value around 25 for variable2 is actually quite bad. In the above example I have assumed that the value zero is the worst possible value, but that may not always be the case."
  },
  {
    "objectID": "scalingFunctions.html#linear-with-defined-lower-limit",
    "href": "scalingFunctions.html#linear-with-defined-lower-limit",
    "title": "6  Scaling functions",
    "section": "6.2 Linear, with defined lower limit",
    "text": "6.2 Linear, with defined lower limit\nWe can also say that the worst possible condition for these variables is not zero, but for example say that it is 5 for variable1 and 28 for variable2.\n\ndat$referenceLow1 <- 5\ndat$referenceLow2 <- 28\n\nWe can then normalise the data between these two reference values.\n\ndat$indicator1_LowHigh <- (dat$variable1-dat$referenceLow1)/(dat$referenceHigh1 - dat$referenceLow1)\ndat$indicator1_LowHigh[dat$indicator1_LowHigh <0] <- 0\ndat$indicator1_LowHigh[dat$indicator1_LowHigh >1] <- 1\n\ndat$indicator2_LowHigh <- (dat$variable2-dat$referenceLow2)/(dat$referenceHigh2 - dat$referenceLow2)\ndat$indicator2_LowHigh[dat$indicator2_LowHigh <0] <- 0\ndat$indicator2_LowHigh[dat$indicator2_LowHigh >1] <- 1\n\n\nggplot(dat)+\n  geom_point(\n    aes(x = variable1, y = indicator1_LowHigh, fill = indicator1_LowHigh),\n             colour = myColour,\n             size   = mySize,\n             alpha  = myAlpha,\n             shape  = myShape)+\n  geom_vline(xintercept = 16,\n             linetype = \"dashed\",\n             size =2)+\n  geom_vline(xintercept = 5,\n             linetype = \"dashed\",\n             size =2)+\n  \n  geom_point(aes(x = variable2, y = indicator2_LowHigh, fill = indicator2_LowHigh),\n             colour = myColour,\n             size   = mySize,\n             alpha  = myAlpha,\n             shape  = myShape)+\n  geom_vline(xintercept = 35,\n             linetype = \"dashed\",\n             size =2)+\n  geom_vline(xintercept = 28,\n             linetype = \"dashed\",\n             size =2)+\n  ylab(\"Indicator values\")+\n  xlab(\"Variable values\")+\n  \n  scale_fill_gradient(\"Indicator values\", low = low, high = high)"
  },
  {
    "objectID": "scalingFunctions.html#break-point-scaling",
    "href": "scalingFunctions.html#break-point-scaling",
    "title": "6  Scaling functions",
    "section": "6.3 Break point scaling",
    "text": "6.3 Break point scaling\nWe can also define a threshold for good ecological condition. Lets for example say that for variable1, ecosystem function really declines when the variable shows values below 9.\n\ndat$thr1 <- 9\n\nThen we can normalise again, using what I refer to as break point normalisation. For the maths, see here.\n\ndat$indicator1_breakPoint <- ifelse(\n  dat$variable1 < dat$thr1,\n    ((dat$variable1-dat$referenceLow1)/(dat$thr1 - dat$referenceLow1))*(0.6-0)+0,\n    ((dat$variable1-dat$thr1)/(dat$referenceHigh1 - dat$thr1))*(1-0.6)+0.6\n  )\n\ndat$indicator1_breakPoint[dat$indicator1_breakPoint<0] <- 0\ndat$indicator1_breakPoint[dat$indicator1_breakPoint>1] <- 1\n\n\nggplot(dat)+\n  geom_point(\n    aes(x = variable1, y = indicator1_breakPoint, fill = indicator1_breakPoint),\n             colour = myColour,\n             size   = mySize,\n             alpha  = myAlpha,\n             shape  = myShape)+\n  geom_vline(xintercept = dat$referenceHigh1[1],\n             linetype = \"dashed\",\n             size =2)+\n  geom_vline(xintercept = dat$referenceLow1,\n             linetype = \"dashed\",\n             size =2)+\n  geom_segment(aes(x = thr1, y = 0, xend = thr1, yend = 0.6),\n               linetype=\"solid\",\n               size=1.5)+\n  geom_segment(aes(x = 0, y = 0.6, xend = thr1, yend = 0.6),\n               linetype=\"solid\",\n               size=1.5)+\n  \n  ylab(\"Indicator values\")+\n  xlab(\"Variable values\")+\n  \n  scale_fill_gradient(\"Indicator values\", low = low, high = high)\n\n\n\n\nThe solid lines point to the indicator value where the variable equals the threshold value."
  },
  {
    "objectID": "scalingFunctions.html#two-sided-indicator",
    "href": "scalingFunctions.html#two-sided-indicator",
    "title": "6  Scaling functions",
    "section": "6.4 Two-sided indicator",
    "text": "6.4 Two-sided indicator\nAn indicator may have an optimum value somewhere in the middle of its range, rather than a max or min value. You can then define a two-sided indicator. Lets say that variable2 is optimal when its at a level of 30, and values either lower or high are both bad.\n\ndat$referenceMid2 <- 30\n\n\ndat$indicator2_twoSided <- ifelse(\n  dat$variable2<dat$referenceMid2,\n    (dat$variable2-dat$referenceLow2)/(dat$referenceMid2-dat$referenceLow2),\n    ((dat$variable2-dat$referenceMid2)/(dat$referenceHigh2-dat$referenceMid2))*(-1)+1\n  )\n\n# truncating\ndat$indicator2_twoSided[dat$indicator2_twoSided<0] <- 0\ndat$indicator2_twoSided[dat$indicator2_twoSided>1] <- 1\n\n\nggplot(dat)+\n  geom_point(\n    aes(x = variable2, y = indicator2_twoSided, fill = indicator2_twoSided),\n             colour = myColour,\n             size   = mySize,\n             alpha  = myAlpha,\n             shape  = myShape)+\n  geom_vline(xintercept = dat$referenceMid2[1],\n             linetype = \"dashed\",\n             size =2)+\n  geom_vline(xintercept = dat$referenceLow2[1],\n             linetype = \"dashed\",\n             size =2)+\n  geom_vline(xintercept = dat$referenceHigh2[1],\n             linetype = \"dashed\",\n             size =2)+\n \n  ylab(\"Indicator values\")+\n  xlab(\"Variable values\")+\n  \n  scale_fill_gradient(\"Indicator values\", low = low, high = high)"
  },
  {
    "objectID": "scalingFunctions.html#sigmoid-transformation",
    "href": "scalingFunctions.html#sigmoid-transformation",
    "title": "6  Scaling functions",
    "section": "6.5 Sigmoid transformation",
    "text": "6.5 Sigmoid transformation\nThere are many other, non-linear ways to normalise an indicator. The correct choice for scaling function varies between indicators and depends on the nature of the indicator and what it represents, but also on the uncertainty around the reference values. Personally, I think the sigmoid function often makes a lot a sense. It is less sensitive to changes around the min and max reference values. A slight deviation from the reference condition should perhaps not often not be described as a true reduction in condition. This is true for example when reference communities (ecosystems defined as having, or representing, good condition) themselves show variation in the variable values, yet the reference value is fixed. A linear scaling will in these cases lead to what is referred to as underestimation biaz (making thing look worse than they really are).\nThe equation for the sigmoid transformation that I use here comes from Oliver at al. (2021); Eq. 1, Supplemetary Information S2.\n\ndat$indicator1_sigmoid <- 100.68*(1-exp(-5*(dat$indicator1_LowHigh)^2.5))/100\n\nFinding the transformed indicator value when the variable equals the threshold\n\nsigmoid_thr <- 100.68*(1-exp(-5*((dat$thr1[1]-dat$referenceLow1[1])/(dat$referenceHigh1[1]-dat$referenceLow1[1]))^2.5))/100\n\n\nggplot(dat)+\n  geom_point(\n    aes(x = variable1, y = indicator1_sigmoid, fill = indicator1_sigmoid),\n             colour = myColour,\n             size   = mySize,\n             alpha  = myAlpha,\n             shape  = myShape)+\n  \n  geom_vline(xintercept = dat$referenceLow1[1],\n             linetype = \"dashed\",\n             size =2)+\n  geom_vline(xintercept = dat$referenceHigh1[1],\n             linetype = \"dashed\",\n             size =2)+\n  \n  geom_segment(aes(x = thr1, y = 0, xend = thr1, yend = sigmoid_thr),\n               linetype=\"solid\",\n               size=1)+\n  geom_segment(aes(x = 0, y = sigmoid_thr, xend = thr1, yend = sigmoid_thr),\n               linetype=\"solid\",\n               size=1)+\n  \n  \n  ylab(\"Indicator values\")+\n  xlab(\"Variable values\")+\n  \n  scale_fill_gradient(\"Indicator values\", low = low, high = high)\n\n\n\n\nThe solid helperlines point to the indicator value where the variable value equals the threshold. Later we will shift the values so that the indicator value becomes 0.6 at this point.\nAlso plotted against the linearly normalised indicator values:\n\nggplot(dat)+\n  geom_point(\n    aes(x = indicator1_LowHigh, y = indicator1_sigmoid, fill = indicator1_sigmoid),\n             colour = myColour,\n             size   = mySize,\n             alpha  = myAlpha,\n             shape  = myShape)+\n  \n  geom_vline(xintercept = 0.6,\n             linetype = \"dashed\",\n             size =2)+\n   geom_hline(yintercept = 0.6,\n             linetype = \"dashed\",\n             size =2)+\n  \n  ylab(\"Sigmoid-transformed\\nIndicator values\")+\n  xlab(\"Linear indicatior values\")+\n  \n  scale_fill_gradient(\"Indicator values\", low = low, high = high)\n\n\n\n\nThe dotted helper lines selve as visual guides to judge how different a scaled indicator value of 0.6 is for the two approaches.\n\n6.5.1 Accounting for the threshold value\nWe can account for the threshold for good ecological condition when applying sigmoid transformation like this\n\ndat$indicator1_sigmoid_thr <- ifelse(\n  dat$variable1<dat$thr1,\n    ((dat$indicator1_sigmoid-0)/(sigmoid_thr-0))*(0.6-0)+0,\n    ((dat$indicator1_sigmoid-sigmoid_thr)/(1-sigmoid_thr))*(1-0.6)+0.6\n  )\nggplot(dat)+\n  geom_point(\n    aes(x = variable1, y = indicator1_sigmoid),\n             fill   = \"grey\", \n             colour = myColour,\n             size   = 5,\n             alpha  = myAlpha,\n             shape  = myShape)+\n  \n  geom_point(\n    aes(x = variable1, y = indicator1_sigmoid_thr, fill = indicator1_sigmoid_thr),\n             colour = myColour,\n             size   = mySize,\n             alpha  = myAlpha,\n             shape  = myShape)+\n  \n  geom_vline(xintercept = dat$referenceLow1[1],\n             linetype = \"dashed\",\n             size =1)+\n  geom_vline(xintercept = dat$referenceHigh1[1],\n             linetype = \"dashed\",\n             size =1)+\n  \n  geom_segment(aes(x = 0, y = sigmoid_thr, xend = thr1, yend = sigmoid_thr),\n               linetype=\"solid\",\n               colour = \"grey\",\n               size=1)+\n  \n  geom_segment(aes(x = thr1, y = 0, xend = thr1, yend = 0.6),\n               linetype=\"solid\",\n               size=1)+\n  geom_segment(aes(x = 0, y = 0.6, xend = thr1, yend = 0.6),\n               linetype=\"solid\",\n               size=1)+\n  \n  \n  ylab(\"Indicator values\")+\n  xlab(\"Variable values\")+\n  \n  scale_fill_gradient(\"Indicator values\", low = low, high = high)\n\n\n\n\nThe grey circles and horizonal line correspons to the sigmoid transformation without any adjustment for the threshold value."
  },
  {
    "objectID": "scalingFunctions.html#exponential-functoins",
    "href": "scalingFunctions.html#exponential-functoins",
    "title": "6  Scaling functions",
    "section": "6.6 Exponential functoins",
    "text": "6.6 Exponential functoins\nHere are two examples of exponential transformation that can also be used:\n\ndat$indicator1_expConvex <- dat$indicator1_LowHigh^0.5\ndat$indicator1_expConcave <- dat$indicator1_LowHigh^2\n\n\nggplot(dat)+\n  geom_point(\n    aes(x = variable1, y = indicator1_expConvex, fill = indicator1_expConvex),\n             colour = myColour,\n             size   = mySize,\n             alpha  = myAlpha,\n             shape  = myShape)+\n  geom_point(\n    aes(x = variable1, y = indicator1_expConcave, fill = indicator1_expConcave),\n             colour = myColour,\n             size   = mySize,\n             alpha  = myAlpha,\n             shape  = myShape)+\n  \n  geom_vline(xintercept = dat$referenceLow1[1],\n             linetype = \"dashed\",\n             size =1)+\n  geom_vline(xintercept = dat$referenceHigh1[1],\n             linetype = \"dashed\",\n             size =1)+\n  ylab(\"Indicator values\")+\n  xlab(\"Variable values\")+\n  \n  scale_fill_gradient(\"Indicator values\", low = low, high = high)"
  },
  {
    "objectID": "medianSummerTemperature.html#introduction",
    "href": "medianSummerTemperature.html#introduction",
    "title": "3  Median Summer Temperature",
    "section": "3.1 Introduction",
    "text": "3.1 Introduction\nThis chapters describes the workflow for an indicator describing the median summer temperature. For a more comprehensive documentation on the development of the workflow itself, see here. The data comes from interpolated climate surfaces from SeNorge which contain one 1x1km raster for each day since 1957 to present. The reference levels are extracted from the time period 1961-1990 (a temporal reference condition).\nWorkflow\n\nCollate variable data series, ending up with one raster per year after aggregating across days within a year\nCalculate spatially explicit reference values by aggregating across the years 1961-1990. The upper reference value is equal to the median value of this period, and the lower reference values (two-sided) is equal to 5 SD units. The indicator value is the mean over a five year period.\nCalculate indicator values through spatially explicit rescaling based on the reference values\nMask by ecosystem type (This step is not yet done as we do not have ready available ecosystem maps)\nAggregate in space (to accounting areas) and take the mean over a five year period to get final indicator values\nMake trend figure and spatially aggregated maps"
  },
  {
    "objectID": "medianSummerTemperature.html#about-the-underlying-data",
    "href": "medianSummerTemperature.html#about-the-underlying-data",
    "title": "3  Median Summer Temperature",
    "section": "3.2 About the underlying data",
    "text": "3.2 About the underlying data\nThe data is in a raster format and extends back to 1957 in the form of multiple interpolated climate variables. The spatial resolution is 1 x 1 km.\n\n3.2.1 Representativity in time and space\nThe data includes the last normal period (1961-1990) which defines the reference condition for climate variables. Therefore the temporal resolution is very good. Also considering the daily resolution of the data.\nSpatially, a 1x1 km resolution is sufficient for most climate variables, esp. in homogeneous terrain, but this needs to be evaluation for each variable and scenario specifically.\n\n\n3.2.2 Original units\nVaried. Specified below for each parameter.\n\n\n3.2.3 Temporal coverage\n1957 - present\n\n\n3.2.4 Additional comments about the data set\nThe data format has recently changed from .BIL to .nc (netcdf) and now a single file contains all the rasters for one year (365 days), and sometimes for multiple variables also."
  },
  {
    "objectID": "medianSummerTemperature.html#ecosystem-characteristic",
    "href": "medianSummerTemperature.html#ecosystem-characteristic",
    "title": "3  Median Summer Temperature",
    "section": "3.3 Ecosystem characteristic",
    "text": "3.3 Ecosystem characteristic\n\n3.3.1 Norwegian standard\nThese variables typically will fall under the abiotiske egenskaper class.\n\n\n3.3.2 SEEA EA\nIn SEEA EA, these variables will typically fall under A1 - Physical state characteristics."
  },
  {
    "objectID": "medianSummerTemperature.html#collinearities-with-other-indicators",
    "href": "medianSummerTemperature.html#collinearities-with-other-indicators",
    "title": "3  Median Summer Temperature",
    "section": "3.4 Collinearities with other indicators",
    "text": "3.4 Collinearities with other indicators\nClimate variables are most likely to be correlated with each other (e.g. temperature and snow). Also, some climate variables are better classed as pressure indicators, and these might have a causal association with several condition indicators."
  },
  {
    "objectID": "medianSummerTemperature.html#reference-condition-and-values",
    "href": "medianSummerTemperature.html#reference-condition-and-values",
    "title": "3  Median Summer Temperature",
    "section": "3.5 Reference condition and values",
    "text": "3.5 Reference condition and values\n\n3.5.1 Reference condition\nThe reference condition for climate variables is defined as the normal period 1961-1990.\n\n\n3.5.2 Reference values, thresholds for defining good ecological condition, minimum and/or maximum values\n\nUn-scaled indicator value = median value over 5 year periods (5 years being a pragmatic choice. It is long enough to smooth out a lot of inter-annual variation, and it’s long enough to enable estimating errors)\nUpper reference level (best possible condition) = median value from the reference period\nThresholds for good ecosystem condition = 2 standard deviation units away from the upper reference level for the climate variable during the reference period.\nLower reference values (two-directional) = 5 standard deviation units for the climate variable during the reference period (implies linear scaling).\n\nThe choice to use 2 SD units as the threshold values is a subjective choice in many ways, and not founded in any empirical or known relationship between the indicators and ecosystem integrity. The value comes from the common practice of calling something extreme weather when it is outside 2 SD units of the current running average. So, if the indicator value today is <0.6 it implies that the mean for that variable over the last year would have been referred to as extreme if it had occurred between 1961 and 1990. This is I think a conservative threshold, since one would/could call it extreme if only one year is outside the 2SD range, and having the mean of 5 years being outside this range is really extreme."
  },
  {
    "objectID": "medianSummerTemperature.html#uncertainties",
    "href": "medianSummerTemperature.html#uncertainties",
    "title": "3  Median Summer Temperature",
    "section": "3.6 Uncertainties",
    "text": "3.6 Uncertainties\nFor the indicator map (1 x 1 km raster) there is no uncertainty associated with the indicator values. For aggregated indicator values (e.g. for regions), the uncertainty in the indicator value is calculated from the spatial variation in the indicator values via bootstrapping. This might, however, be changed later to the temporal variation between the five years of each period."
  },
  {
    "objectID": "medianSummerTemperature.html#references",
    "href": "medianSummerTemperature.html#references",
    "title": "3  Median Summer Temperature",
    "section": "3.7 References",
    "text": "3.7 References\nhttps://senorge.no/\nrr and tm are being download from: https://thredds.met.no/thredds/catalog/senorge/seNorge_2018/Archive/catalog.html\n\n3.7.1 Additional resources\nStars package\nR as a GIS for economists chapter 7"
  },
  {
    "objectID": "medianSummerTemperature.html#analyses",
    "href": "medianSummerTemperature.html#analyses",
    "title": "3  Median Summer Temperature",
    "section": "3.8 Analyses",
    "text": "3.8 Analyses\n\n3.8.1 Data set\nThe data is downloaded to a local NINA server, and updated regularly.\n\npath <- ifelse(dir == \"C:\", \n      \"R:/GeoSpatialData/Meteorology/Norway_SeNorge2018_v22.09/Original\",\n      \"/data/R/GeoSpatialData/Meteorology/Norway_SeNorge2018_v22.09/Original\")\n\nThis folder contains folder for the different parameters\n\n(files <- list.files(path))\n\n [1] \"age\"        \"fsw\"        \"gwb_eva\"    \"gwb_gwtcl\"  \"gwb_q\"     \n [6] \"gwb_sssdev\" \"gwb_sssrel\" \"lwc\"        \"qsw\"        \"rr_tm\"     \n[11] \"sd\"         \"sdfsw\"      \"swe\"       \n\n\nWe are interested in tm, which is temperatur in celcius. For some reason the same variable is called tg in the data itself.\n\n3.8.1.1 Regions\nImporting a shape file with the regional delineation.\n\nreg <- sf::st_read(\"data/regions.shp\", options = \"ENCODING=UTF8\")\n\noptions:        ENCODING=UTF8 \nReading layer `regions' from data source \n  `/data/scratch/Matt_bookdown__debug/ecosystemCondition/data/regions.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5 features and 2 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -99551.21 ymin: 6426048 xmax: 1121941 ymax: 7962744\nProjected CRS: ETRS89 / UTM zone 33N\n\n#st_crs(reg)\n\nOutline of Norway\n\nnor <- sf::st_read(\"data/outlineOfNorway_EPSG25833.shp\")\n\nReading layer `outlineOfNorway_EPSG25833' from data source \n  `/data/scratch/Matt_bookdown__debug/ecosystemCondition/data/outlineOfNorway_EPSG25833.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1 feature and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -113472.7 ymin: 6448359 xmax: 1114618 ymax: 7939917\nProjected CRS: ETRS89 / UTM zone 33N\n\n\nRemove marine areas from regions\n\nreg <- st_intersection(reg, nor)\n\n\ntm_shape(reg) +\n  tm_polygons(col=\"region\")\n\n\n\n\nFive accounting areas (regions) in Norway.\n\n\n\n\n\n\n3.8.1.2 Ecosystem map\nComing soon ….\nThe climate indicators need to be masked with ecosystem type maps. This step is part of this chapter.\n\n\n\n3.8.2 Conceptual workflow\nThe general, the conceptual workflow is like this:\n\nCollate variable data series\n\nImport .nc files (loop though year 1961-1990) and subset to the correct attribute\nFilter data by dates (optional) (dplyr::filter). This means reading all 365 rasters into memory, and it is much quicker to filter out the correct rasters in the importing step above (see examples later in this chapter)\nAggregate across time within a year (stars::st_apply). This is the most time consuming operation in the workflow.\nJoin all data into one data cube (stars:c)\n\nCalculate reference values\n\nAggregate (st_apply) across reference years (dplyr::filter) to get median and sd values\nJoin with existing data cube (stars:c)\n\nCalculate indicator values\n\nNormalize climate variable at the individual grid cell level using the three reference values (mutate(across()))\n\nMask by ecosystem type (This could also be done in step one, but it doesn’t speed things up to set some cells to NA)\nAggregate in space (to accounting areas) (zonal statistics)\n\nAggregate across 5 year time steps to smooth out random inter-annual variation and leave climate signal\nIntersect with accounting area polygons exactextrar::exact_extract and get mean/median and (spatial) sd. (Alternatively, get temporal sd at the grid cell level in the step above.)\n\nMake trend figure and spatially aggregated maps\n\n\n\n3.8.3 Step 1 - temporal aggregation within a year\n\npath <- path <- ifelse(dir == \"C:\", \n      \"R:/\",\n      \"/data/R/\")\n  \npath2 <- paste0(path, \"GeoSpatialData/Meteorology/Norway_SeNorge2018_v22.09/Original/rr_tm/\")\n\nmyFiles <- list.files(path2, pattern=\".nc$\",full.names = T)\n# The last file (the last year) is incomplete and don't include all julian dates that we select below, so I will not include it:\nmyFiles <- myFiles[-length(myFiles)]\n\nreal_temp_summer <- NULL\n\n# set up parallel cluster using 10 cores\ncl <- makeCluster(10L)\n\n# Get julian days after defining months\ntemp <- stars::read_ncdf(paste(myFiles[1]), var=\"tg\")\nstart_month_num <-  6\nend_month_num <- 8\n\njulian_start <- yday(st_get_dimension_values(temp, \"time\")[1] %m+%\n                       months(+start_month_num))\njulian_end <- yday(st_get_dimension_values(temp, \"time\")[1] %m+%\n                     months(+end_month_num))\nstep <- julian_end-julian_start\n\n\n\nfor(i in 1:length(myFiles)){\n  \n  tic(\"init\")\n  temp <- stars::read_ncdf(paste(myFiles[i]), var=\"tg\", proxy=F,\n                           ncsub = cbind(start = c(1, 1, julian_start), \n                              count = c(NA, NA, step)))\n  year_temp <- year(st_get_dimension_values(temp, \"time\")[1])\n  print(year_temp)\n  lookup <- setNames(\"mean\", paste0(\"v_\", year_temp)) \n    # Perhaps leave out the v_ to get a numeric vector instead, \n    # which is easier to subset\n  st_crs(temp) <- 25833\n  toc()\n\n  tic(\"filter and st_apply\")\n  temp <- temp %>%\n    #filter(time %within% myInterval) %>%\n    st_apply(1:2, mean, CLUSTER = cl) %>%\n    rename(all_of(lookup)) \n  toc()\n  \n  tic(\"c()\")\n  real_temp_summer <- c(temp, real_temp_summer)\n  #rm(temp)\n  toc()\n}\n\ntic(\"Merge\")\nreal_temp_summer <- real_temp_summer %>%\n  merge(name = \"Year\") %>%\n  setNames(\"climate_variable\")\ntoc()\n\nstopCluster(cl)\n\nThis takes about 20 sec per file/year, or 22 min on total. That is not too bad. About 6000 rasters are read into memory. Here’s a test for the effect of splitting over more cores.\n\nwrite_stars(real_temp_summer, \"/data/P-Prosjekter2/41201785_okologisk_tilstand_2022_2023/data/climate_indicators/aggregated_climate_time_series/real_temp_summer.tiff\")\n\nNote that GTiff automatically renames the third dimension band and also renames the attribute. I can rename them.\n\nsummer_median_temp <- real_temp_summer %>% \n  st_set_dimensions(names = c(\"x\", \"y\", \"v_YEAR\")) %>%\n  setNames(\"temperature\")\n\n\nggplot()+\n  geom_stars(data = summer_median_temp[,,,c(1,11,66)], downsample = c(10, 10, 0)) +\n  coord_equal() +\n  theme_void() +\n  scale_fill_viridis_c(option = \"D\") +  \n  scale_x_discrete(expand = c(0, 0)) +\n  scale_y_discrete(expand = c(0, 0))+\n  facet_wrap(~v_YEAR)\n\n\n\n\nShowing three random slices of the year dimension.\n\n\n\n\n\n\n3.8.4 Step 2 - calculate reference values\nWe need to first to define a reference period and then to subset our data summer_median_temp.\nFirst we need to rename our dimension values and turn them back into dates.\n\nnew_dims <- as.Date(paste0(\n  substr(st_get_dimension_values(summer_median_temp, \"v_YEAR\"), 3, 6), \"-01-01\"))\nsummer_median_temp_ref <- summer_median_temp %>%\n  st_set_dimensions(\"v_YEAR\", values = new_dims)\n\nThen I can filter to leave only the reference period.\n\nsummer_median_temp_ref <- summer_median_temp_ref %>%\n  filter(v_YEAR %within% interval(\"1961-01-01\", \"1990-12-31\"))\nst_get_dimension_values(summer_median_temp_ref, \"v_YEAR\")\n\n [1] \"1990-01-01\" \"1989-01-01\" \"1988-01-01\" \"1987-01-01\" \"1986-01-01\"\n [6] \"1985-01-01\" \"1984-01-01\" \"1983-01-01\" \"1982-01-01\" \"1981-01-01\"\n[11] \"1980-01-01\" \"1979-01-01\" \"1978-01-01\" \"1977-01-01\" \"1976-01-01\"\n[16] \"1975-01-01\" \"1974-01-01\" \"1973-01-01\" \"1972-01-01\" \"1971-01-01\"\n[21] \"1970-01-01\" \"1969-01-01\" \"1968-01-01\" \"1967-01-01\" \"1966-01-01\"\n[26] \"1965-01-01\" \"1964-01-01\" \"1963-01-01\" \"1962-01-01\" \"1961-01-01\"\n\n\nAnd then we calculate the median and sd like above\n\nmedian_sd <- function(x) { c(median = median(x), sd = sd(x))}\n\n\nsystem.time({\ncl <- makeCluster(10L)\nsummer_median_temp_ref <- summer_median_temp_ref %>%\n  st_apply(c(\"x\", \"y\"), \n           FUN =  median_sd,\n           CLUSTER = cl)\nstopCluster(cl)\n})\n\n\n\n\nuser\nsystem\nelapsed\n\n\n\n\n9.624\n6.069\n20.903\n\n\n\n\nwrite_stars(summer_median_temp_ref, \"/data/P-Prosjekter2/41201785_okologisk_tilstand_2022_2023/data/climate_indicators/aggregated_climate_time_series/summer_median_temp_ref.tiff\")\n\nPivot and turn dimension into attributes, and rename attributes:\n\nsummer_median_temp_ref_long <- summer_median_temp_ref %>% \n  split(\"band\") %>%\n  setNames(c(\"reference_upper\", \"sd\"))\n\n\ntmap_arrange(\ntm_shape(st_downsample(summer_median_temp_ref_long, 10))+\n  tm_raster(\"reference_upper\")\n,\ntm_shape(st_downsample(summer_median_temp_ref_long, 10))+\n  tm_raster(\"sd\",\n            palette = \"-viridis\")\n)\n\n\n\n\nShowing the upper reference levels and the standard deviation from actual data of median summer temperatures.\n\n\n\n\nI need to combine the variables and the ref values in one data cube\n\ny_var <- summer_median_temp %>%\n  split(\"v_YEAR\") %>%\n  c(summer_median_temp_ref_long)\n\n\n\n3.8.5 Step 3 - normalise variable\n\n# select the columns to normalise\ncols <- names(y_var)[!names(y_var) %in% c(\"reference_upper\", \"sd\") ]\ncols_new <- cols\nnames(cols_new) <- gsub(\"v_\", \"i_\", cols)\n\n\n# The break point scaling is actually not needed here, since \n# having the lower ref value to be 5 sd implies that the threshold is\n# 2 sd in a linear scaling.\n\nsystem.time(\ny_var_norm <- y_var %>%\n  mutate(reference_low = reference_upper - 5*sd ) %>%\n  mutate(reference_low2 = reference_upper + 5*sd ) %>%\n  mutate(threshold_low = reference_upper -2*sd ) %>%\n  mutate(threshold_high = reference_upper +2*sd ) %>%\n  mutate(across(all_of(cols), ~ \n                  if_else(.x < reference_upper,\n                  if_else(.x < threshold_low, \n                                        (.x - reference_low) / (threshold_low - reference_low),\n                                        (.x - threshold_low) / (reference_upper - threshold_low),\n                                        ),\n                  if_else(.x > threshold_high, \n                                        (reference_low2 - .x) / (reference_low2 - threshold_high),\n                                        (threshold_high - .x) / (threshold_high - reference_upper),\n                                        )\n                ))) %>%\n  mutate(across(all_of(cols), ~ if_else(.x > 1, 1, .x))) %>%\n  mutate(across(all_of(cols), ~ if_else(.x < 0, 0, .x))) %>%\n  rename(all_of(cols_new)) %>%\n  c(select(y_var, all_of(cols)))\n)\n\n\n\n\nuser\nsystem\nelapsed\n\n\n\n\n14.803\n2.717\n17.512\n\n\n\n\ngc()\nsaveRDS(y_var_norm, \"/data/P-Prosjekter2/41201785_okologisk_tilstand_2022_2023/data/climate_indicators/aggregated_climate_time_series/summer_median_temp_normalised.RData\")\n\n# Tiff dont allow for multiple attributes:\n#write_stars(y_var_norm, \"/data/P-Prosjekter2/41201785_okologisk_tilstand_2022_2023/data/climate_indicators/aggregated_climate_time_series/summer_median_temp_normalised.tiff\")\n\n\nlims <- c(-5, 22)\n\nggarrange(\nggplot() + \n  geom_stars(data = st_downsample(y_var_norm[\"v_1970\"],10)) +\n  coord_equal() +\n  theme_void() +\n  scale_fill_viridis_c(option = \"D\",\n                       limits = lims) +  \n  scale_x_discrete(expand = c(0, 0)) +\n  scale_y_discrete(expand = c(0, 0))\n,\nggplot() + \n  geom_stars(data = st_downsample(y_var_norm[\"reference_upper\"], 10)) +\n  coord_equal() +\n  theme_void() +\n  scale_fill_viridis_c(option = \"D\",\n                       limits = lims) +  \n  scale_x_discrete(expand = c(0, 0)) +\n  scale_y_discrete(expand = c(0, 0))\n,\nggplot() + \n  geom_stars(data = st_downsample(y_var_norm[\"reference_low\"], 10)) +\n  coord_equal() +\n  theme_void() +\n  scale_fill_viridis_c(option = \"D\",\n                       limits = lims) +  \n  scale_x_discrete(expand = c(0, 0)) +\n  scale_y_discrete(expand = c(0, 0))\n,\n\nggplot() + \n  geom_stars(data = st_downsample(y_var_norm[\"reference_low2\"], 10)) +\n  coord_equal() +\n  theme_void() +\n  scale_fill_viridis_c(option = \"D\",\n                       limits = lims) +  \n  scale_x_discrete(expand = c(0, 0)) +\n  scale_y_discrete(expand = c(0, 0))\n,\n\nggplot() + \n  geom_stars(data = st_downsample(y_var_norm[\"i_1970\"],10)) +\n  coord_equal() +\n  theme_void() +\n  scale_fill_viridis_c(option = \"A\",\n                       limits = c(0, 1)) +  \n  scale_x_discrete(expand = c(0, 0)) +\n  scale_y_discrete(expand = c(0, 0))\n, ncol=2, nrow=3, align = \"hv\"\n)\n\n\n\n\nExample showing median summer tempretur in 1970, the upper and lwoer reference temperture, i.e. median and 5 SD units of the temperature between 1961-1990, and finally, the scaled indicator values.\n\n\n\n\nThe real indicator values should be means over 5 year periods. Calculating a running mean for all time steps is too time consuming. Therefore, the scaled, regional indicator values will be calculated for distinct time steps. The time series can perhaps still be presented with yearly resolution.\n\n\n3.8.6 Step 4 - Mask with ecosystem delineation map\nThis step we simply ignore for now. It should be relatively easy to do, when we have the maps.\n\n\n3.8.7 Step 5 - Make figures\nTo plot time series I first need to do a spatial aggregation.\n\nsystem.time(\nregional_means <- rast(y_var_norm) %>%\n  exact_extract(reg, fun = 'mean', append_cols = \"region\", progress=T) %>%\n  setNames(c(\"region\", names(y_var_norm)))\n  )\n\nuser; system; elapsed: 7.603; 3.071; 10.697\nI could also get the sd like this, if I wanted to base the indicator uncertainty on a measure of spatial variation:\n\nsystem.time(\nregional_sd <- rast(y_var_norm) %>%\n  exact_extract(reg, fun = 'stdev', append_cols = \"region\", progress=T) %>%\n  setNames(c(\"region\", names(y_var_norm)))\n  )\n\nuser; system; elapsed: 7.420; 2.921; 10.355\n\nsaveRDS(regional_means, \"temp/regional_means.rds\")\nsaveRDS(regional_sd, \"temp/regional_sd.rds\")\n\nReshape and plot\n\ndiv <- c(\"reference_upper\",\n         \"reference_low\",\n         \"reference_low2\",\n         \"threshold_low\",\n         \"threshold_high\",\n         \"sd\")\n\ntemp <- regional_means %>%\n  as.data.frame() %>%\n  select(region, div)\n  \nregional_means_long <- regional_means %>%\n  as.data.frame() %>%\n  select(!all_of(div)) %>%\n  pivot_longer(!region) %>%\n  separate(name, into=c(\"type\", \"year\")) %>%\n  pivot_wider(#id_cols = region,\n              names_from = type)  %>%\n  left_join(temp, by=join_by(region)) %>% \n  mutate(diff = v-reference_upper) %>%\n  mutate(threshold_low_centered = threshold_low-reference_upper) %>%\n  mutate(threshold_high_centered = threshold_high-reference_upper)\n\n#Adding the spatial sd\n#(\n#regional_means_long <- regional_sd %>%\n#  select(!all_of(div)) %>%\n#  pivot_longer(!region) %>%\n#  separate(name, into=c(\"type\", \"year\")) %>%\n#  pivot_wider(names_from = type) %>%\n#  rename(i_sd = i,\n#         v_sd = v) %>%\n#  left_join(regional_means_long, by=join_by(region, year))\n#)\n\n\nregOrder = c(\"Østlandet\",\"Sørlandet\",\"Vestlandet\",\"Midt-Norge\",\"Nord-Norge\")\n\nregional_means_long %>%\n  mutate(col = if_else(diff>0, \"1\", \"2\")) %>%\n  ggplot(aes(x = as.numeric(year), \n           y = diff, fill = col))+\n  geom_bar(stat=\"identity\")+\n  geom_hline(aes(yintercept = threshold_low_centered),\n        linetype=2)+\n  geom_hline(aes(yintercept = threshold_high_centered),\n        linetype=2)+\n  geom_segment(x = 1961, xend=1990,\n               y = 0, yend = 0,\n               linewidth=2)+\n  scale_fill_hue(l=70, c=60)+\n  theme_bw(base_size = 12)+\n  ylab(\"Sommertemperatur\\navvik fra 1961-1990\")+\n  xlab(\"\")+\n  guides(fill=\"none\")+\n  facet_wrap( .~ factor(region, levels = regOrder),\n              ncol=3,\n              scales = \"free_y\")\n\n\n\n\nTimes series for median summer temperature centered on the median value during the reference period. The reference period is indicated with a thick horizontal line. Dottet horisontal lines are 2 sd units for the reference period.\n\n\n\n\nThen we can take the mean and sd over the last 5 years and add to a spatial representation.\n\n(\ni_aggregatedToPeriods <- regional_means_long %>%\n  mutate(year = as.numeric(year)) %>%\n  mutate(period = case_when(\n    year %between% c(2018, 2022) ~ \"2018-2022\",\n    year %between% c(2013, 2017) ~ \"2013-2017\",\n    year %between% c(2008, 2012) ~ \"2008-2012\",\n    year %between% c(2003, 2007) ~ \"2003-2007\",\n    .default = \"pre 2003\"\n  )) %>%\n  mutate(period_rank = case_when(\n   period == \"2018-2022\" ~ 5,\n   period == \"2013-2017\" ~ 4,\n   period == \"2008-2012\" ~ 3,\n   period == \"2003-2007\" ~ 2,\n    .default = 1\n  )) %>%\n  group_by(region, period, period_rank) %>%\n  summarise(indicator = mean(i),\n            sd = sd(i)\n            # If I inluded a spatial measure for the uncertainty, here is how I would carry the errors:\n            #spatial_sd = sqrt(sum(i_sd^2))/length(i_sd)\n            )\n)\n\n`summarise()` has grouped output by 'region', 'period'. You can override using\nthe `.groups` argument.\n\n\n# A tibble: 25 × 5\n# Groups:   region, period [25]\n   region     period    period_rank indicator     sd\n   <chr>      <chr>           <dbl>     <dbl>  <dbl>\n 1 Midt-Norge 2003-2007           2     0.427 0.139 \n 2 Midt-Norge 2008-2012           3     0.573 0.0992\n 3 Midt-Norge 2013-2017           4     0.536 0.212 \n 4 Midt-Norge 2018-2022           5     0.607 0.179 \n 5 Midt-Norge pre 2003            1     0.642 0.182 \n 6 Nord-Norge 2003-2007           2     0.460 0.149 \n 7 Nord-Norge 2008-2012           3     0.675 0.0602\n 8 Nord-Norge 2013-2017           4     0.641 0.127 \n 9 Nord-Norge 2018-2022           5     0.625 0.110 \n10 Nord-Norge pre 2003            1     0.625 0.194 \n# ℹ 15 more rows\n\n\n\nlabs <- unique(i_aggregatedToPeriods$period[order(i_aggregatedToPeriods$period_rank)])\n\ni_aggregatedToPeriods %>%\n  ggplot(aes(x = period_rank, \n             y = indicator,\n             colour=region))+\n  geom_line() +\n  geom_point() +\n  geom_errorbar(aes(ymin=indicator-sd, \n                    ymax=indicator+sd), \n                    width=.2,\n                 position=position_dodge(0.2)) +\n  theme_bw(base_size = 12)+\n  scale_x_continuous(breaks = 1:5,\n                     labels = labs)+\n  labs(x = \"\", y = \"indikatorverdi\")\n\n\n\n\nScaled indicator values, aggregated over 5 year intervals. Errors represent temporal variation (standard errors) within regions and across 5 years.\n\n\n\n\nFinally, I can add these values to the sp object with the accounting areas.\n\nreg2 <- reg %>%\n  left_join(i_aggregatedToPeriods[i_aggregatedToPeriods$period_rank==5,], by=join_by(region))\n\n\nmyCol <- \"RdYlGn\"\nmyCol2 <- \"-RdYlGn\"\n\ntm_main <- tm_shape(reg2)+\n  tm_polygons(col=\"indicator\",\n              title=\"Indikator:\\nsommertemperatur\",\n    palette = myCol,\n    style=\"fixed\",\n    breaks = seq(0,1,.2)) \n  \ntm_inset <- tm_shape(reg2)+\n  tm_polygons(col=\"sd\",\n              title=\"SD\",\n              palette = myCol2,\n              style=\"cont\")+\n  tm_layout(legend.format = list(digits=2))\n\ntmap_arrange(tm_main, \n             tm_inset)\n\n\n\n\nSummer tempreature indicator values for five accounting areas in Norway. SD is the spatial variation."
  }
]